nohup: ignoring input
[2025-08-30 17:43:18,701] [INFO] [real_accelerator.py:260:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-08-30 17:43:29,428] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[2025-08-30 17:43:31,954] [WARNING] [runner.py:220:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2025-08-30 17:43:31,955] [INFO] [runner.py:610:main] cmd = /home/jovyan/miniconda/envs/pytorch/bin/python3 -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN119 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None train_cosmopedia_v2.py
[2025-08-30 17:43:35,778] [INFO] [real_accelerator.py:260:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-08-30 17:43:43,929] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[2025-08-30 17:43:45,417] [INFO] [launch.py:146:main] WORLD INFO DICT: {'localhost': [0, 1, 2, 3, 4, 5, 6, 7]}
[2025-08-30 17:43:45,417] [INFO] [launch.py:152:main] nnodes=1, num_local_procs=8, node_rank=0
[2025-08-30 17:43:45,417] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1, 2, 3, 4, 5, 6, 7]})
[2025-08-30 17:43:45,417] [INFO] [launch.py:164:main] dist_world_size=8
[2025-08-30 17:43:45,417] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
[2025-08-30 17:43:45,418] [INFO] [launch.py:256:main] process 665491 spawned with command: ['/home/jovyan/miniconda/envs/pytorch/bin/python3', '-u', 'train_cosmopedia_v2.py', '--local_rank=0']
[2025-08-30 17:43:45,420] [INFO] [launch.py:256:main] process 665492 spawned with command: ['/home/jovyan/miniconda/envs/pytorch/bin/python3', '-u', 'train_cosmopedia_v2.py', '--local_rank=1']
[2025-08-30 17:43:45,421] [INFO] [launch.py:256:main] process 665493 spawned with command: ['/home/jovyan/miniconda/envs/pytorch/bin/python3', '-u', 'train_cosmopedia_v2.py', '--local_rank=2']
[2025-08-30 17:43:45,421] [INFO] [launch.py:256:main] process 665494 spawned with command: ['/home/jovyan/miniconda/envs/pytorch/bin/python3', '-u', 'train_cosmopedia_v2.py', '--local_rank=3']
[2025-08-30 17:43:45,422] [INFO] [launch.py:256:main] process 665495 spawned with command: ['/home/jovyan/miniconda/envs/pytorch/bin/python3', '-u', 'train_cosmopedia_v2.py', '--local_rank=4']
[2025-08-30 17:43:45,423] [INFO] [launch.py:256:main] process 665496 spawned with command: ['/home/jovyan/miniconda/envs/pytorch/bin/python3', '-u', 'train_cosmopedia_v2.py', '--local_rank=5']
[2025-08-30 17:43:45,424] [INFO] [launch.py:256:main] process 665497 spawned with command: ['/home/jovyan/miniconda/envs/pytorch/bin/python3', '-u', 'train_cosmopedia_v2.py', '--local_rank=6']
[2025-08-30 17:43:45,425] [INFO] [launch.py:256:main] process 665498 spawned with command: ['/home/jovyan/miniconda/envs/pytorch/bin/python3', '-u', 'train_cosmopedia_v2.py', '--local_rank=7']
[2025-08-30 17:43:52,092] [INFO] [real_accelerator.py:260:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-08-30 17:43:52,174] [INFO] [real_accelerator.py:260:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-08-30 17:43:52,258] [INFO] [real_accelerator.py:260:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-08-30 17:43:52,310] [INFO] [real_accelerator.py:260:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-08-30 17:43:52,315] [INFO] [real_accelerator.py:260:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-08-30 17:43:52,365] [INFO] [real_accelerator.py:260:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-08-30 17:43:52,374] [INFO] [real_accelerator.py:260:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-08-30 17:43:52,402] [INFO] [real_accelerator.py:260:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-08-30 17:43:57,413] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[2025-08-30 17:43:57,569] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[2025-08-30 17:43:58,038] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[2025-08-30 17:43:58,075] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[2025-08-30 17:43:58,117] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[2025-08-30 17:43:58,207] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[2025-08-30 17:43:58,821] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[2025-08-30 17:43:58,846] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[2025-08-30 17:44:11,477] [INFO] [logging.py:107:log_dist] [Rank -1] DeepSpeed info: version=0.17.5, git-hash=unknown, git-branch=unknown
[2025-08-30 17:44:11,477] [INFO] [comm.py:821:init_distributed] cdb=None
[2025-08-30 17:44:11,553] [INFO] [logging.py:107:log_dist] [Rank -1] DeepSpeed info: version=0.17.5, git-hash=unknown, git-branch=unknown
[2025-08-30 17:44:11,553] [INFO] [comm.py:821:init_distributed] cdb=None
[2025-08-30 17:44:12,102] [INFO] [logging.py:107:log_dist] [Rank -1] DeepSpeed info: version=0.17.5, git-hash=unknown, git-branch=unknown
[2025-08-30 17:44:12,102] [INFO] [comm.py:821:init_distributed] cdb=None
[2025-08-30 17:44:12,122] [INFO] [logging.py:107:log_dist] [Rank -1] DeepSpeed info: version=0.17.5, git-hash=unknown, git-branch=unknown
[2025-08-30 17:44:12,122] [INFO] [comm.py:821:init_distributed] cdb=None
[2025-08-30 17:44:13,496] [INFO] [logging.py:107:log_dist] [Rank -1] DeepSpeed info: version=0.17.5, git-hash=unknown, git-branch=unknown
[2025-08-30 17:44:13,496] [INFO] [comm.py:821:init_distributed] cdb=None
[2025-08-30 17:44:14,693] [INFO] [logging.py:107:log_dist] [Rank -1] DeepSpeed info: version=0.17.5, git-hash=unknown, git-branch=unknown
[2025-08-30 17:44:14,693] [INFO] [comm.py:821:init_distributed] cdb=None
[2025-08-30 17:44:18,407] [INFO] [logging.py:107:log_dist] [Rank -1] DeepSpeed info: version=0.17.5, git-hash=unknown, git-branch=unknown
[2025-08-30 17:44:18,407] [INFO] [comm.py:821:init_distributed] cdb=None
[2025-08-30 17:44:19,167] [INFO] [logging.py:107:log_dist] [Rank -1] DeepSpeed info: version=0.17.5, git-hash=unknown, git-branch=unknown
[2025-08-30 17:44:19,167] [INFO] [comm.py:821:init_distributed] cdb=None
[2025-08-30 17:44:19,167] [INFO] [comm.py:852:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2025-08-30 17:44:25,043] [INFO] [config.py:684:__init__] Config mesh_device None world_size = 8
[2025-08-30 17:44:25,043] [INFO] [config.py:684:__init__] Config mesh_device None world_size = 8
[2025-08-30 17:44:25,045] [INFO] [config.py:684:__init__] Config mesh_device None world_size = 8
[2025-08-30 17:44:25,047] [INFO] [config.py:684:__init__] Config mesh_device None world_size = 8
[2025-08-30 17:44:25,048] [INFO] [config.py:684:__init__] Config mesh_device None world_size = 8
[2025-08-30 17:44:25,048] [INFO] [config.py:684:__init__] Config mesh_device None world_size = 8
[2025-08-30 17:44:25,049] [INFO] [config.py:684:__init__] Config mesh_device None world_size = 8
[2025-08-30 17:44:25,057] [INFO] [config.py:684:__init__] Config mesh_device None world_size = 8
[2025-08-30 17:44:25,931] [INFO] [engine.py:1356:_configure_distributed_model] ********** distributed groups summary **********
	 self.dp_world_size=8
	 self.mp_world_size=1
	 self.seq_dp_world_size=8
	 self.sequence_parallel_size=1
***********************************************
[2025-08-30 17:44:26,675] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
Installed CUDA version 12.4 does not match the version torch was compiled with 12.8 but since the APIs are compatible, accepting this combination
[rank3]:W0830 17:44:31.467000 665494 site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[rank3]:W0830 17:44:31.467000 665494 site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
Installed CUDA version 12.4 does not match the version torch was compiled with 12.8 but since the APIs are compatible, accepting this combination
ninja: no work to do.
Time to load cpu_adam op: 2.7333083152770996 seconds
Adam Optimizer #0 is created with AVX512 arithmetic capability.
Config: alpha=0.000300, betas=(0.900000, 0.950000), weight_decay=0.100000, adam_w=1
[2025-08-30 17:44:31,492] [INFO] [config.py:684:__init__] Config mesh_device None world_size = 8
Time to load cpu_adam op: 2.8815407752990723 seconds
Adam Optimizer #0 is created with AVX512 arithmetic capability.
Config: alpha=0.000300, betas=(0.900000, 0.950000), weight_decay=0.100000, adam_w=1
[2025-08-30 17:44:31,590] [INFO] [config.py:684:__init__] Config mesh_device None world_size = 8
Installed CUDA version 12.4 does not match the version torch was compiled with 12.8 but since the APIs are compatible, accepting this combination
[rank6]:W0830 17:44:32.045000 665497 site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[rank6]:W0830 17:44:32.045000 665497 site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
ninja: no work to do.
Time to load cpu_adam op: 3.162550449371338 seconds
Adam Optimizer #0 is created with AVX512 arithmetic capability.
Config: alpha=0.000300, betas=(0.900000, 0.950000), weight_decay=0.100000, adam_w=1
[2025-08-30 17:44:32,069] [INFO] [config.py:684:__init__] Config mesh_device None world_size = 8
Installed CUDA version 12.4 does not match the version torch was compiled with 12.8 but since the APIs are compatible, accepting this combination
[rank1]:W0830 17:44:32.236000 665492 site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[rank1]:W0830 17:44:32.236000 665492 site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
ninja: no work to do.
Time to load cpu_adam op: 3.373603582382202 seconds
Adam Optimizer #0 is created with AVX512 arithmetic capability.
Config: alpha=0.000300, betas=(0.900000, 0.950000), weight_decay=0.100000, adam_w=1
[2025-08-30 17:44:32,259] [INFO] [config.py:684:__init__] Config mesh_device None world_size = 8
Installed CUDA version 12.4 does not match the version torch was compiled with 12.8 but since the APIs are compatible, accepting this combination
[rank4]:W0830 17:44:32.593000 665495 site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[rank4]:W0830 17:44:32.593000 665495 site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
ninja: no work to do.
Time to load cpu_adam op: 3.71734356880188 seconds
Adam Optimizer #0 is created with AVX512 arithmetic capability.
Config: alpha=0.000300, betas=(0.900000, 0.950000), weight_decay=0.100000, adam_w=1
[2025-08-30 17:44:32,620] [INFO] [config.py:684:__init__] Config mesh_device None world_size = 8
Installed CUDA version 12.4 does not match the version torch was compiled with 12.8 but since the APIs are compatible, accepting this combination
[rank7]:W0830 17:44:32.763000 665498 site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[rank7]:W0830 17:44:32.763000 665498 site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
Installed CUDA version 12.4 does not match the version torch was compiled with 12.8 but since the APIs are compatible, accepting this combination
Installed CUDA version 12.4 does not match the version torch was compiled with 12.8 but since the APIs are compatible, accepting this combination
ninja: no work to do.
Time to load cpu_adam op: 3.8805594444274902 seconds
Adam Optimizer #0 is created with AVX512 arithmetic capability.
Config: alpha=0.000300, betas=(0.900000, 0.950000), weight_decay=0.100000, adam_w=1
[2025-08-30 17:44:32,793] [INFO] [config.py:684:__init__] Config mesh_device None world_size = 8
Time to load cpu_adam op: 3.9713451862335205 seconds
Adam Optimizer #0 is created with AVX512 arithmetic capability.
Config: alpha=0.000300, betas=(0.900000, 0.950000), weight_decay=0.100000, adam_w=1
[2025-08-30 17:44:32,877] [INFO] [logging.py:107:log_dist] [Rank 0] Using DeepSpeed Optimizer param name adamw as basic optimizer
[2025-08-30 17:44:32,877] [INFO] [logging.py:107:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
Time to load cpu_adam op: 3.966134548187256 seconds
Adam Optimizer #0 is created with AVX512 arithmetic capability.
Config: alpha=0.000300, betas=(0.900000, 0.950000), weight_decay=0.100000, adam_w=1
[2025-08-30 17:44:32,885] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam
[2025-08-30 17:44:32,885] [INFO] [utils.py:59:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>
[2025-08-30 17:44:32,885] [INFO] [logging.py:107:log_dist] [Rank 0] Creating fp16 ZeRO stage 3 optimizer, MiCS is enabled False, Hierarchical params gather False
[2025-08-30 17:44:32,885] [INFO] [logging.py:107:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 3 optimizer
[2025-08-30 17:44:32,891] [INFO] [config.py:684:__init__] Config mesh_device None world_size = 8
[2025-08-30 17:44:33,143] [INFO] [utils.py:781:see_memory_usage] Stage 3 initialize beginning
[2025-08-30 17:44:33,143] [INFO] [utils.py:782:see_memory_usage] MA 0.56 GB         Max_MA 0.56 GB         CA 0.58 GB         Max_CA 1 GB 
[2025-08-30 17:44:33,144] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 50.29 GB, percent = 5.0%
[2025-08-30 17:44:33,145] [INFO] [stage3.py:186:__init__] Reduce bucket size 500000000
[2025-08-30 17:44:33,145] [INFO] [stage3.py:187:__init__] Prefetch bucket size 50000000
[2025-08-30 17:44:33,290] [INFO] [utils.py:781:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]
[2025-08-30 17:44:33,291] [INFO] [utils.py:782:see_memory_usage] MA 0.56 GB         Max_MA 0.56 GB         CA 0.58 GB         Max_CA 1 GB 
[2025-08-30 17:44:33,292] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 50.3 GB, percent = 5.0%
[2025-08-30 17:44:33,294] [INFO] [config.py:684:__init__] Config mesh_device None world_size = 8
Parameter Offload - Persistent parameters statistics: param_count = 109, numel = 55936
[2025-08-30 17:44:38,180] [INFO] [utils.py:781:see_memory_usage] DeepSpeedZeRoOffload initialize [end]
[2025-08-30 17:44:38,181] [INFO] [utils.py:782:see_memory_usage] MA 0.06 GB         Max_MA 0.56 GB         CA 0.58 GB         Max_CA 1 GB 
[2025-08-30 17:44:38,181] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 51.11 GB, percent = 5.1%
[2025-08-30 17:44:38,273] [INFO] [utils.py:781:see_memory_usage] Before creating fp16 partitions
[2025-08-30 17:44:38,273] [INFO] [utils.py:782:see_memory_usage] MA 0.06 GB         Max_MA 0.06 GB         CA 0.58 GB         Max_CA 1 GB 
[2025-08-30 17:44:38,274] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 51.12 GB, percent = 5.1%
[2025-08-30 17:44:42,454] [INFO] [utils.py:781:see_memory_usage] After creating fp16 partitions: 1
[2025-08-30 17:44:42,455] [INFO] [utils.py:782:see_memory_usage] MA 0.06 GB         Max_MA 0.06 GB         CA 0.58 GB         Max_CA 1 GB 
[2025-08-30 17:44:42,455] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 52.33 GB, percent = 5.2%
[2025-08-30 17:44:42,563] [INFO] [utils.py:781:see_memory_usage] Before creating fp32 partitions
[2025-08-30 17:44:42,563] [INFO] [utils.py:782:see_memory_usage] MA 0.06 GB         Max_MA 0.06 GB         CA 0.58 GB         Max_CA 1 GB 
[2025-08-30 17:44:42,563] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 52.34 GB, percent = 5.2%
[2025-08-30 17:44:42,719] [INFO] [utils.py:781:see_memory_usage] After creating fp32 partitions
[2025-08-30 17:44:42,719] [INFO] [utils.py:782:see_memory_usage] MA 0.06 GB         Max_MA 0.06 GB         CA 0.58 GB         Max_CA 1 GB 
[2025-08-30 17:44:42,719] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 52.44 GB, percent = 5.2%
[2025-08-30 17:44:42,890] [INFO] [utils.py:781:see_memory_usage] Before initializing optimizer states
[2025-08-30 17:44:42,890] [INFO] [utils.py:782:see_memory_usage] MA 0.06 GB         Max_MA 0.06 GB         CA 0.58 GB         Max_CA 1 GB 
[2025-08-30 17:44:42,890] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 53.58 GB, percent = 5.3%
[2025-08-30 17:44:43,130] [INFO] [utils.py:781:see_memory_usage] After initializing optimizer states
[2025-08-30 17:44:43,130] [INFO] [utils.py:782:see_memory_usage] MA 0.06 GB         Max_MA 0.06 GB         CA 0.58 GB         Max_CA 1 GB 
[2025-08-30 17:44:43,131] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 53.53 GB, percent = 5.3%
[2025-08-30 17:44:43,131] [INFO] [stage3.py:554:_setup_for_real_optimizer] optimizer state initialized
[2025-08-30 17:44:43,365] [WARNING] [lr_schedules.py:858:get_lr] Attempting to get learning rate from scheduler before it has started
[2025-08-30 17:44:43,365] [WARNING] [lr_schedules.py:858:get_lr] Attempting to get learning rate from scheduler before it has started
[2025-08-30 17:44:43,365] [WARNING] [lr_schedules.py:858:get_lr] Attempting to get learning rate from scheduler before it has started
[2025-08-30 17:44:43,365] [WARNING] [lr_schedules.py:858:get_lr] Attempting to get learning rate from scheduler before it has started
[2025-08-30 17:44:43,365] [WARNING] [lr_schedules.py:858:get_lr] Attempting to get learning rate from scheduler before it has started
[2025-08-30 17:44:43,365] [WARNING] [lr_schedules.py:858:get_lr] Attempting to get learning rate from scheduler before it has started
[2025-08-30 17:44:43,366] [WARNING] [lr_schedules.py:858:get_lr] Attempting to get learning rate from scheduler before it has started
[2025-08-30 17:44:43,500] [INFO] [utils.py:781:see_memory_usage] After initializing ZeRO optimizer
[2025-08-30 17:44:43,501] [INFO] [utils.py:782:see_memory_usage] MA 0.99 GB         Max_MA 1.62 GB         CA 2.12 GB         Max_CA 2 GB 
[2025-08-30 17:44:43,501] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 53.48 GB, percent = 5.3%
[2025-08-30 17:44:43,501] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedZeroOptimizer_Stage3
[2025-08-30 17:44:43,501] [WARNING] [lr_schedules.py:858:get_lr] Attempting to get learning rate from scheduler before it has started
[2025-08-30 17:44:43,501] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed using configured LR scheduler = WarmupCosineLR
[2025-08-30 17:44:43,501] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupCosineLR object at 0x7f1f7df8f7a0>
[2025-08-30 17:44:43,501] [INFO] [logging.py:107:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0], mom=[[0.9, 0.95]]
[2025-08-30 17:44:43,502] [INFO] [logging.py:107:log_dist] [Rank 0] [TorchCheckpointEngine] Initialized with serialization = True
[2025-08-30 17:44:43,502] [INFO] [config.py:954:print] DeepSpeedEngine configuration:
[2025-08-30 17:44:43,502] [INFO] [config.py:958:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2025-08-30 17:44:43,502] [INFO] [config.py:958:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'intra_op_parallelism': 1, 'single_submit': False, 'overlap_events': True, 'use_gds': False}
[2025-08-30 17:44:43,502] [INFO] [config.py:958:print]   amp_enabled .................. False
[2025-08-30 17:44:43,502] [INFO] [config.py:958:print]   amp_params ................... False
[2025-08-30 17:44:43,502] [INFO] [config.py:958:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2025-08-30 17:44:43,502] [INFO] [config.py:958:print]   bfloat16_config .............. enabled=True immediate_grad_update=False check_grad_overflow=False
[2025-08-30 17:44:43,502] [INFO] [config.py:958:print]   checkpoint_config ............ {'tag_validation': 'WARN', 'checkpoint_serialization': True, 'writer': None}
[2025-08-30 17:44:43,502] [INFO] [config.py:958:print]   checkpoint_parallel_write_pipeline  False
[2025-08-30 17:44:43,502] [INFO] [config.py:958:print]   checkpoint_tag_validation_enabled  True
[2025-08-30 17:44:43,502] [INFO] [config.py:958:print]   checkpoint_tag_validation_fail  False
[2025-08-30 17:44:43,502] [INFO] [config.py:958:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f1f84ecfd70>
[2025-08-30 17:44:43,502] [INFO] [config.py:958:print]   communication_data_type ...... None
[2025-08-30 17:44:43,502] [INFO] [config.py:958:print]   compile_config ............... deepcompile=False free_activation=False offload_activation=False offload_opt_states=False double_buffer=True symmetric_memory=False debug_log=False offload_parameters=False sync_before_reduce=False sync_after_reduce=False sync_before_allgather=False sync_after_allgather=False keep_int_input_tensors=True keep_all_input_tensors=False
[2025-08-30 17:44:43,502] [INFO] [config.py:958:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2025-08-30 17:44:43,502] [INFO] [config.py:958:print]   curriculum_enabled_legacy .... False
[2025-08-30 17:44:43,502] [INFO] [config.py:958:print]   curriculum_params_legacy ..... False
[2025-08-30 17:44:43,502] [INFO] [config.py:958:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'pin_memory': False, 'curriculum_learning': {'enabled': False}, 'dynamic_batching': {'enabled': False, 'lr_scaling_method': 'linear', 'min_batch_size': 1, 'max_batch_size': None, 'sequence_picking_order': 'dataloader', 'verbose': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2025-08-30 17:44:43,502] [INFO] [config.py:958:print]   data_efficiency_enabled ...... False
[2025-08-30 17:44:43,502] [INFO] [config.py:958:print]   dataloader_drop_last ......... False
[2025-08-30 17:44:43,502] [INFO] [config.py:958:print]   disable_allgather ............ False
[2025-08-30 17:44:43,502] [INFO] [config.py:958:print]   dump_state ................... False
[2025-08-30 17:44:43,502] [INFO] [config.py:958:print]   eigenvalue_enabled ........... False
[2025-08-30 17:44:43,502] [INFO] [config.py:958:print]   eigenvalue_gas_boundary_resolution  1
[2025-08-30 17:44:43,502] [INFO] [config.py:958:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2025-08-30 17:44:43,502] [INFO] [config.py:958:print]   eigenvalue_layer_num ......... 0
[2025-08-30 17:44:43,502] [INFO] [config.py:958:print]   eigenvalue_max_iter .......... 100
[2025-08-30 17:44:43,502] [INFO] [config.py:958:print]   eigenvalue_stability ......... 1e-06
[2025-08-30 17:44:43,502] [INFO] [config.py:958:print]   eigenvalue_tol ............... 0.01
[2025-08-30 17:44:43,502] [INFO] [config.py:958:print]   eigenvalue_verbose ........... False
[2025-08-30 17:44:43,502] [INFO] [config.py:958:print]   elasticity_enabled ........... False
[2025-08-30 17:44:43,503] [INFO] [config.py:958:print]   float16_config ............... enabled=False auto_cast=False loss_scale=0.0 initial_scale_power=16 loss_scale_window=1000 hysteresis=2 consecutive_hysteresis=False min_loss_scale=1 fp16_master_weights_and_grads=False
[2025-08-30 17:44:43,503] [INFO] [config.py:958:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2025-08-30 17:44:43,503] [INFO] [config.py:958:print]   global_rank .................. 0
[2025-08-30 17:44:43,503] [INFO] [config.py:958:print]   grad_accum_dtype ............. None
[2025-08-30 17:44:43,503] [INFO] [config.py:958:print]   gradient_accumulation_steps .. 4
[2025-08-30 17:44:43,503] [INFO] [config.py:958:print]   gradient_clipping ............ 1.0
[2025-08-30 17:44:43,503] [INFO] [config.py:958:print]   gradient_predivide_factor .... 1.0
[2025-08-30 17:44:43,503] [INFO] [config.py:958:print]   graph_harvesting ............. False
[2025-08-30 17:44:43,503] [INFO] [config.py:958:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2025-08-30 17:44:43,503] [INFO] [config.py:958:print]   load_universal_checkpoint .... False
[2025-08-30 17:44:43,503] [INFO] [config.py:958:print]   memory_breakdown ............. False
[2025-08-30 17:44:43,503] [INFO] [config.py:958:print]   mics_hierarchial_params_gather  False
[2025-08-30 17:44:43,503] [INFO] [config.py:958:print]   mics_shard_size .............. -1
[2025-08-30 17:44:43,503] [INFO] [config.py:958:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') comet=CometConfig(enabled=False, samples_log_interval=100, project=None, workspace=None, api_key=None, experiment_name=None, experiment_key=None, online=None, mode=None) wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName')
[2025-08-30 17:44:43,503] [INFO] [config.py:958:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2025-08-30 17:44:43,503] [INFO] [config.py:958:print]   optimizer_legacy_fusion ...... False
[2025-08-30 17:44:43,503] [INFO] [config.py:958:print]   optimizer_name ............... adamw
[2025-08-30 17:44:43,503] [INFO] [config.py:958:print]   optimizer_params ............. {'lr': 0.0003, 'betas': [0.9, 0.95], 'eps': 1e-08, 'weight_decay': 0.1}
[2025-08-30 17:44:43,503] [INFO] [config.py:958:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2025-08-30 17:44:43,503] [INFO] [config.py:958:print]   pld_enabled .................. False
[2025-08-30 17:44:43,503] [INFO] [config.py:958:print]   pld_params ................... False
[2025-08-30 17:44:43,503] [INFO] [config.py:958:print]   prescale_gradients ........... False
[2025-08-30 17:44:43,503] [INFO] [config.py:958:print]   scheduler_name ............... WarmupCosineLR
[2025-08-30 17:44:43,503] [INFO] [config.py:958:print]   scheduler_params ............. {'warmup_num_steps': 500, 'total_num_steps': 20000}
[2025-08-30 17:44:43,503] [INFO] [config.py:958:print]   seq_parallel_communication_data_type  torch.float32
[2025-08-30 17:44:43,503] [INFO] [config.py:958:print]   sparse_attention ............. None
[2025-08-30 17:44:43,503] [INFO] [config.py:958:print]   sparse_gradients_enabled ..... False
[2025-08-30 17:44:43,503] [INFO] [config.py:958:print]   steps_per_print .............. 25
[2025-08-30 17:44:43,503] [INFO] [config.py:958:print]   tensor_parallel_config ....... dtype=torch.float16 autotp_size=0 tp_overlap_comm=False tensor_parallel=TPConfig(tp_size=1, tp_grain_size=1, mpu=None, tp_group=None) injection_policy_tuple=None keep_module_on_host=False replace_with_kernel_inject=False
[2025-08-30 17:44:43,503] [INFO] [config.py:958:print]   timers_config ................ enabled=True synchronized=True
[2025-08-30 17:44:43,503] [INFO] [config.py:958:print]   torch_autocast_dtype ......... None
[2025-08-30 17:44:43,503] [INFO] [config.py:958:print]   torch_autocast_enabled ....... False
[2025-08-30 17:44:43,503] [INFO] [config.py:958:print]   torch_autocast_lower_precision_safe_modules  None
[2025-08-30 17:44:43,503] [INFO] [config.py:958:print]   train_batch_size ............. 32
[2025-08-30 17:44:43,503] [INFO] [config.py:958:print]   train_micro_batch_size_per_gpu  1
[2025-08-30 17:44:43,503] [INFO] [config.py:958:print]   use_data_before_expert_parallel_  False
[2025-08-30 17:44:43,503] [INFO] [config.py:958:print]   use_node_local_storage ....... False
[2025-08-30 17:44:43,503] [INFO] [config.py:958:print]   wall_clock_breakdown ......... False
[2025-08-30 17:44:43,503] [INFO] [config.py:958:print]   weight_quantization_config ... None
[2025-08-30 17:44:43,503] [INFO] [config.py:958:print]   world_size ................... 8
[2025-08-30 17:44:43,503] [INFO] [config.py:958:print]   zero_allow_untested_optimizer  False
[2025-08-30 17:44:43,503] [INFO] [config.py:958:print]   zero_config .................. stage=3 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='cpu', nvme_path=None, buffer_count=5, buffer_size=100000000, max_in_cpu=1000000000, pin_memory=True) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=True, pipeline_read=False, pipeline_write=False, fast_init=False, ratio=1.0) zenflow=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50000000 param_persistence_threshold=100000 model_persistence_threshold=9223372036854775807 max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=True module_granularity_threshold=0 use_all_reduce_for_fetch_params=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False zeropp_loco_param=None mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True log_trace_cache_warnings=False
[2025-08-30 17:44:43,503] [INFO] [config.py:958:print]   zero_enabled ................. True
[2025-08-30 17:44:43,503] [INFO] [config.py:958:print]   zero_force_ds_cpu_optimizer .. True
[2025-08-30 17:44:43,503] [INFO] [config.py:958:print]   zero_optimization_stage ...... 3
[2025-08-30 17:44:43,503] [INFO] [config.py:944:print_user_config]   json = {
    "train_batch_size": 32, 
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 4, 
    "optimizer": {
        "type": "AdamW", 
        "params": {
            "lr": 0.0003, 
            "betas": [0.9, 0.95], 
            "eps": 1e-08, 
            "weight_decay": 0.1
        }
    }, 
    "scheduler": {
        "type": "WarmupCosineLR", 
        "params": {
            "warmup_num_steps": 500, 
            "total_num_steps": 2.000000e+04
        }
    }, 
    "bf16": {
        "enabled": true
    }, 
    "zero_optimization": {
        "stage": 3, 
        "offload_optimizer": {
            "device": "cpu", 
            "pin_memory": true
        }, 
        "offload_param": {
            "device": "cpu", 
            "pin_memory": true
        }, 
        "overlap_comm": true, 
        "contiguous_gradients": true, 
        "sub_group_size": 1.000000e+09, 
        "reduce_bucket_size": "auto", 
        "stage3_prefetch_bucket_size": "auto", 
        "stage3_param_persistence_threshold": "auto", 
        "stage3_max_live_parameters": 1.000000e+09, 
        "stage3_max_reuse_distance": 1.000000e+09, 
        "stage3_gather_16bit_weights_on_model_save": true
    }, 
    "gradient_clipping": 1.0, 
    "wall_clock_breakdown": false, 
    "steps_per_print": 25, 
    "flops_profiler": {
        "enabled": false
    }
}
[DeepSpeed] engine initialized. device=cuda:0, local_rank=0
[step 1] loss=1152.0000 lr=0.00e+00
[2025-08-30 17:45:05,062] [WARNING] [stage3.py:2160:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
[step 50] loss=484.0000 lr=1.20e-04
[2025-08-30 17:48:08,607] [INFO] [logging.py:107:log_dist] [Rank 0] step=25, skipped=0, lr=[0.0001553859442408974], mom=[[0.9, 0.95]]
[2025-08-30 17:48:08,608] [INFO] [timer.py:264:stop] epoch=0/micro_step=100/global_step=25, RunningAvgSamplesPerSec=4.210217833996664, CurrSamplesPerSec=4.21143649290346, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 100] loss=356.0000 lr=1.55e-04
[step 150] loss=286.0000 lr=1.74e-04
[2025-08-30 17:51:20,308] [INFO] [logging.py:107:log_dist] [Rank 0] step=50, skipped=0, lr=[0.00018884648606022435], mom=[[0.9, 0.95]]
[2025-08-30 17:51:20,309] [INFO] [timer.py:264:stop] epoch=0/micro_step=200/global_step=50, RunningAvgSamplesPerSec=4.204957994757284, CurrSamplesPerSec=4.22454006371965, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 200] loss=238.0000 lr=1.89e-04
[step 250] loss=193.0000 lr=1.99e-04
[2025-08-30 17:54:32,115] [INFO] [logging.py:107:log_dist] [Rank 0] step=75, skipped=0, lr=[0.00020841964827834265], mom=[[0.9, 0.95]]
[2025-08-30 17:54:32,115] [INFO] [timer.py:264:stop] epoch=0/micro_step=300/global_step=75, RunningAvgSamplesPerSec=4.201976937602258, CurrSamplesPerSec=4.231476970558204, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 300] loss=191.0000 lr=2.08e-04
[step 350] loss=172.0000 lr=2.16e-04
[2025-08-30 17:57:43,875] [INFO] [logging.py:107:log_dist] [Rank 0] step=100, skipped=0, lr=[0.0002223070278795513], mom=[[0.9, 0.95]]
[2025-08-30 17:57:43,876] [INFO] [timer.py:264:stop] epoch=0/micro_step=400/global_step=100, RunningAvgSamplesPerSec=4.201280300962611, CurrSamplesPerSec=4.223024367170387, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 400] loss=152.0000 lr=2.22e-04
[step 450] loss=115.5000 lr=2.28e-04
[2025-08-30 18:00:55,180] [INFO] [logging.py:107:log_dist] [Rank 0] step=125, skipped=0, lr=[0.00023307891636134616], mom=[[0.9, 0.95]]
[2025-08-30 18:00:55,181] [INFO] [timer.py:264:stop] epoch=0/micro_step=500/global_step=125, RunningAvgSamplesPerSec=4.20311224641273, CurrSamplesPerSec=4.2234938602650685, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 500] loss=106.0000 lr=2.33e-04
[step 550] loss=109.0000 lr=2.38e-04
[2025-08-30 18:04:06,835] [INFO] [logging.py:107:log_dist] [Rank 0] step=150, skipped=0, lr=[0.0002418801900976696], mom=[[0.9, 0.95]]
[2025-08-30 18:04:06,836] [INFO] [timer.py:264:stop] epoch=0/micro_step=600/global_step=150, RunningAvgSamplesPerSec=4.203228159838069, CurrSamplesPerSec=4.210933212872171, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 600] loss=109.5000 lr=2.42e-04
[step 650] loss=96.0000 lr=2.46e-04
[2025-08-30 18:07:18,200] [INFO] [logging.py:107:log_dist] [Rank 0] step=175, skipped=0, lr=[0.00024932156101209924], mom=[[0.9, 0.95]]
[2025-08-30 18:07:18,201] [INFO] [timer.py:264:stop] epoch=0/micro_step=700/global_step=175, RunningAvgSamplesPerSec=4.204608428917109, CurrSamplesPerSec=4.197349545110191, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 700] loss=85.5000 lr=2.49e-04
[step 750] loss=96.0000 lr=2.53e-04
[2025-08-30 18:10:30,309] [INFO] [logging.py:107:log_dist] [Rank 0] step=200, skipped=0, lr=[0.0002557675696988782], mom=[[0.9, 0.95]]
[2025-08-30 18:10:30,310] [INFO] [timer.py:264:stop] epoch=0/micro_step=800/global_step=200, RunningAvgSamplesPerSec=4.202356977471831, CurrSamplesPerSec=4.205575310568756, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 800] loss=98.5000 lr=2.56e-04
[step 850] loss=98.0000 lr=2.59e-04
[2025-08-30 18:13:41,645] [INFO] [logging.py:107:log_dist] [Rank 0] step=225, skipped=0, lr=[0.0002614533523157879], mom=[[0.9, 0.95]]
[2025-08-30 18:13:41,646] [INFO] [timer.py:264:stop] epoch=0/micro_step=900/global_step=225, RunningAvgSamplesPerSec=4.202686296688882, CurrSamplesPerSec=4.208677924769848, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 900] loss=85.0000 lr=2.61e-04
[step 950] loss=93.0000 lr=2.64e-04
[2025-08-30 18:16:53,107] [INFO] [logging.py:107:log_dist] [Rank 0] step=250, skipped=0, lr=[0.000266539458180673], mom=[[0.9, 0.95]]
[2025-08-30 18:16:53,108] [INFO] [timer.py:264:stop] epoch=0/micro_step=1000/global_step=250, RunningAvgSamplesPerSec=4.2026991255750366, CurrSamplesPerSec=4.19498697084423, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 1000] loss=94.5000 lr=2.67e-04
[step 1050] loss=82.0000 lr=2.69e-04
[2025-08-30 18:20:04,587] [INFO] [logging.py:107:log_dist] [Rank 0] step=275, skipped=0, lr=[0.0002711404005874126], mom=[[0.9, 0.95]]
[2025-08-30 18:20:04,588] [INFO] [timer.py:264:stop] epoch=0/micro_step=1100/global_step=275, RunningAvgSamplesPerSec=4.202713342675118, CurrSamplesPerSec=4.214105529532031, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 1100] loss=76.5000 lr=2.71e-04
[step 1150] loss=51.0000 lr=2.73e-04
[2025-08-30 18:23:16,138] [INFO] [logging.py:107:log_dist] [Rank 0] step=300, skipped=0, lr=[0.0002753407319169965], mom=[[0.9, 0.95]]
[2025-08-30 18:23:16,139] [INFO] [timer.py:264:stop] epoch=0/micro_step=1200/global_step=300, RunningAvgSamplesPerSec=4.202616769359133, CurrSamplesPerSec=4.1965476849667525, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 1200] loss=69.0000 lr=2.75e-04
[step 1250] loss=61.0000 lr=2.77e-04
[2025-08-30 18:26:28,053] [INFO] [logging.py:107:log_dist] [Rank 0] step=325, skipped=0, lr=[0.0002792046621796558], mom=[[0.9, 0.95]]
[2025-08-30 18:26:28,054] [INFO] [timer.py:264:stop] epoch=0/micro_step=1300/global_step=325, RunningAvgSamplesPerSec=4.201990262212061, CurrSamplesPerSec=4.207789281630855, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 1300] loss=49.0000 lr=2.79e-04
[step 1350] loss=69.5000 lr=2.81e-04
[2025-08-30 18:29:39,320] [INFO] [logging.py:107:log_dist] [Rank 0] step=350, skipped=0, lr=[0.0002827821028314261], mom=[[0.9, 0.95]]
[2025-08-30 18:29:39,320] [INFO] [timer.py:264:stop] epoch=0/micro_step=1400/global_step=350, RunningAvgSamplesPerSec=4.202429101561947, CurrSamplesPerSec=4.205060651020327, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 1400] loss=64.5000 lr=2.83e-04
[step 1450] loss=44.7500 lr=2.84e-04
[2025-08-30 18:32:50,394] [INFO] [logging.py:107:log_dist] [Rank 0] step=375, skipped=0, lr=[0.00028611262039879136], mom=[[0.9, 0.95]]
[2025-08-30 18:32:50,395] [INFO] [timer.py:264:stop] epoch=0/micro_step=1500/global_step=375, RunningAvgSamplesPerSec=4.203024631359896, CurrSamplesPerSec=4.224249547383963, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 1500] loss=48.5000 lr=2.86e-04
[step 1550] loss=51.2500 lr=2.88e-04
[2025-08-30 18:36:02,118] [INFO] [logging.py:107:log_dist] [Rank 0] step=400, skipped=0, lr=[0.00028922811151820514], mom=[[0.9, 0.95]]
[2025-08-30 18:36:02,119] [INFO] [timer.py:264:stop] epoch=0/micro_step=1600/global_step=400, RunningAvgSamplesPerSec=4.20262060505092, CurrSamplesPerSec=4.186828131272434, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 1600] loss=47.0000 lr=2.89e-04
[step 1650] loss=47.0000 lr=2.91e-04
[2025-08-30 18:39:13,716] [INFO] [logging.py:107:log_dist] [Rank 0] step=425, skipped=0, lr=[0.0002921546655754993], mom=[[0.9, 0.95]]
[2025-08-30 18:39:13,717] [INFO] [timer.py:264:stop] epoch=0/micro_step=1700/global_step=425, RunningAvgSamplesPerSec=4.202447842207522, CurrSamplesPerSec=4.21975012255421, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 1700] loss=38.2500 lr=2.92e-04
[step 1750] loss=39.7500 lr=2.93e-04
[2025-08-30 18:42:24,947] [INFO] [logging.py:107:log_dist] [Rank 0] step=450, skipped=0, lr=[0.00029491389413511485], mom=[[0.9, 0.95]]
[2025-08-30 18:42:24,948] [INFO] [timer.py:264:stop] epoch=0/micro_step=1800/global_step=450, RunningAvgSamplesPerSec=4.2028166321208795, CurrSamplesPerSec=4.089488842575108, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 1800] loss=38.2500 lr=2.95e-04
[step 1850] loss=45.2500 lr=2.96e-04
[2025-08-30 18:45:36,522] [INFO] [logging.py:107:log_dist] [Rank 0] step=475, skipped=0, lr=[0.00029752390044994595], mom=[[0.9, 0.95]]
[2025-08-30 18:45:36,523] [INFO] [timer.py:264:stop] epoch=0/micro_step=1900/global_step=475, RunningAvgSamplesPerSec=4.202864347509413, CurrSamplesPerSec=4.116044842655557, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 1900] loss=32.5000 lr=2.98e-04
[step 1950] loss=27.3750 lr=2.99e-04
[2025-08-30 18:48:47,774] [INFO] [logging.py:107:log_dist] [Rank 0] step=500, skipped=0, lr=[0.0003], mom=[[0.9, 0.95]]
[2025-08-30 18:48:47,775] [INFO] [timer.py:264:stop] epoch=0/micro_step=2000/global_step=500, RunningAvgSamplesPerSec=4.2031057388669595, CurrSamplesPerSec=4.0711180497711705, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 2000] loss=34.5000 lr=3.00e-04
[step 2050] loss=28.2500 lr=3.00e-04
[2025-08-30 18:51:59,275] [INFO] [logging.py:107:log_dist] [Rank 0] step=525, skipped=0, lr=[0.0002999987834561021], mom=[[0.9, 0.95]]
[2025-08-30 18:51:59,278] [INFO] [timer.py:264:stop] epoch=0/micro_step=2100/global_step=525, RunningAvgSamplesPerSec=4.203066166141262, CurrSamplesPerSec=4.205267764601017, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 2100] loss=18.1250 lr=3.00e-04
[step 2150] loss=16.3750 lr=3.00e-04
[2025-08-30 18:55:10,718] [INFO] [logging.py:107:log_dist] [Rank 0] step=550, skipped=0, lr=[0.0002999951338441434], mom=[[0.9, 0.95]]
[2025-08-30 18:55:10,718] [INFO] [timer.py:264:stop] epoch=0/micro_step=2200/global_step=550, RunningAvgSamplesPerSec=4.203176574979728, CurrSamplesPerSec=4.228780694729386, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 2200] loss=15.1875 lr=3.00e-04
[step 2250] loss=7.2500 lr=3.00e-04
[2025-08-30 18:58:22,167] [INFO] [logging.py:107:log_dist] [Rank 0] step=575, skipped=0, lr=[0.00029998905122332876], mom=[[0.9, 0.95]]
[2025-08-30 18:58:22,168] [INFO] [timer.py:264:stop] epoch=0/micro_step=2300/global_step=575, RunningAvgSamplesPerSec=4.203339594247216, CurrSamplesPerSec=4.198254925979943, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 2300] loss=6.8750 lr=3.00e-04
[step 2350] loss=5.8750 lr=3.00e-04
[2025-08-30 19:01:33,673] [INFO] [logging.py:107:log_dist] [Rank 0] step=600, skipped=0, lr=[0.0002999805356923316], mom=[[0.9, 0.95]]
[2025-08-30 19:01:33,674] [INFO] [timer.py:264:stop] epoch=0/micro_step=2400/global_step=600, RunningAvgSamplesPerSec=4.203332874773606, CurrSamplesPerSec=4.227806034176143, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 2400] loss=4.0938 lr=3.00e-04
[step 2450] loss=2.1562 lr=3.00e-04
[2025-08-30 19:04:45,458] [INFO] [logging.py:107:log_dist] [Rank 0] step=625, skipped=0, lr=[0.0002999695873892927], mom=[[0.9, 0.95]]
[2025-08-30 19:04:45,459] [INFO] [timer.py:264:stop] epoch=0/micro_step=2500/global_step=625, RunningAvgSamplesPerSec=4.203100559233824, CurrSamplesPerSec=4.216085060337584, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 2500] loss=1.6328 lr=3.00e-04
[step 2550] loss=3.3125 lr=3.00e-04
[2025-08-30 19:07:56,972] [INFO] [logging.py:107:log_dist] [Rank 0] step=650, skipped=0, lr=[0.0002999562064918177], mom=[[0.9, 0.95]]
[2025-08-30 19:07:56,973] [INFO] [timer.py:264:stop] epoch=0/micro_step=2600/global_step=650, RunningAvgSamplesPerSec=4.203080082697159, CurrSamplesPerSec=4.2112193899139125, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 2600] loss=1.1719 lr=3.00e-04
[step 2650] loss=1.0703 lr=3.00e-04
[2025-08-30 19:11:08,310] [INFO] [logging.py:107:log_dist] [Rank 0] step=675, skipped=0, lr=[0.00029994039321697434], mom=[[0.9, 0.95]]
[2025-08-30 19:11:08,311] [INFO] [timer.py:264:stop] epoch=0/micro_step=2700/global_step=675, RunningAvgSamplesPerSec=4.203244752046783, CurrSamplesPerSec=4.210455545058429, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 2700] loss=1.5078 lr=3.00e-04
[step 2750] loss=0.2090 lr=3.00e-04
[2025-08-30 19:14:19,791] [INFO] [logging.py:107:log_dist] [Rank 0] step=700, skipped=0, lr=[0.00029992214782128873], mom=[[0.9, 0.95]]
[2025-08-30 19:14:19,791] [INFO] [timer.py:264:stop] epoch=0/micro_step=2800/global_step=700, RunningAvgSamplesPerSec=4.203287067866542, CurrSamplesPerSec=4.20813268748417, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 2800] loss=0.5352 lr=3.00e-04
[step 2850] loss=2.8125 lr=3.00e-04
[2025-08-30 19:17:31,066] [INFO] [logging.py:107:log_dist] [Rank 0] step=725, skipped=0, lr=[0.00029990147060074147], mom=[[0.9, 0.95]]
[2025-08-30 19:17:31,067] [INFO] [timer.py:264:stop] epoch=0/micro_step=2900/global_step=725, RunningAvgSamplesPerSec=4.203542931689334, CurrSamplesPerSec=4.237766507569919, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 2900] loss=1.3438 lr=3.00e-04
[step 2950] loss=0.4727 lr=3.00e-04
[2025-08-30 19:20:42,502] [INFO] [logging.py:107:log_dist] [Rank 0] step=750, skipped=0, lr=[0.0002998783618907628], mom=[[0.9, 0.95]]
[2025-08-30 19:20:42,502] [INFO] [timer.py:264:stop] epoch=0/micro_step=3000/global_step=750, RunningAvgSamplesPerSec=4.203544090970945, CurrSamplesPerSec=4.1994196550321385, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 3000] loss=0.2539 lr=3.00e-04
[step 3050] loss=0.4531 lr=3.00e-04
[2025-08-30 19:23:53,729] [INFO] [logging.py:107:log_dist] [Rank 0] step=775, skipped=0, lr=[0.0002998528220662271], mom=[[0.9, 0.95]]
[2025-08-30 19:23:53,729] [INFO] [timer.py:264:stop] epoch=0/micro_step=3100/global_step=775, RunningAvgSamplesPerSec=4.203792143770084, CurrSamplesPerSec=4.217253212059563, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 3100] loss=0.3379 lr=3.00e-04
[step 3150] loss=0.2305 lr=3.00e-04
[2025-08-30 19:27:04,877] [INFO] [logging.py:107:log_dist] [Rank 0] step=800, skipped=0, lr=[0.0002998248515414465], mom=[[0.9, 0.95]]
[2025-08-30 19:27:04,877] [INFO] [timer.py:264:stop] epoch=0/micro_step=3200/global_step=800, RunningAvgSamplesPerSec=4.204013093001995, CurrSamplesPerSec=4.2169015591815855, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 3200] loss=0.1875 lr=3.00e-04
[step 3250] loss=0.3340 lr=3.00e-04
[2025-08-30 19:30:16,250] [INFO] [logging.py:107:log_dist] [Rank 0] step=825, skipped=0, lr=[0.0002997944507701647], mom=[[0.9, 0.95]]
[2025-08-30 19:30:16,251] [INFO] [timer.py:264:stop] epoch=0/micro_step=3300/global_step=825, RunningAvgSamplesPerSec=4.204068912790677, CurrSamplesPerSec=4.236925993322903, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 3300] loss=0.2178 lr=3.00e-04
[step 3350] loss=2.0156 lr=3.00e-04
[2025-08-30 19:33:27,740] [INFO] [logging.py:107:log_dist] [Rank 0] step=850, skipped=0, lr=[0.0002997616202455495], mom=[[0.9, 0.95]]
[2025-08-30 19:33:27,741] [INFO] [timer.py:264:stop] epoch=0/micro_step=3400/global_step=850, RunningAvgSamplesPerSec=4.204056243431559, CurrSamplesPerSec=4.221226163358711, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 3400] loss=3.0469 lr=3.00e-04
[step 3450] loss=0.2773 lr=3.00e-04
[2025-08-30 19:36:39,105] [INFO] [logging.py:107:log_dist] [Rank 0] step=875, skipped=0, lr=[0.0002997263605001842], mom=[[0.9, 0.95]]
[2025-08-30 19:36:39,106] [INFO] [timer.py:264:stop] epoch=0/micro_step=3500/global_step=875, RunningAvgSamplesPerSec=4.204193537128963, CurrSamplesPerSec=4.216763113608128, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 3500] loss=0.1104 lr=3.00e-04
[step 3550] loss=1.3672 lr=3.00e-04
[2025-08-30 19:39:50,420] [INFO] [logging.py:107:log_dist] [Rank 0] step=900, skipped=0, lr=[0.00029968867210606], mom=[[0.9, 0.95]]
[2025-08-30 19:39:50,421] [INFO] [timer.py:264:stop] epoch=0/micro_step=3600/global_step=900, RunningAvgSamplesPerSec=4.2042945074941604, CurrSamplesPerSec=4.201200770705518, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 3600] loss=1.7656 lr=3.00e-04
[step 3650] loss=3.3906 lr=3.00e-04
[2025-08-30 19:43:01,623] [INFO] [logging.py:107:log_dist] [Rank 0] step=925, skipped=0, lr=[0.0002996485556745656], mom=[[0.9, 0.95]]
[2025-08-30 19:43:01,624] [INFO] [timer.py:264:stop] epoch=0/micro_step=3700/global_step=925, RunningAvgSamplesPerSec=4.204502738418045, CurrSamplesPerSec=4.139542867791682, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 3700] loss=0.2266 lr=3.00e-04
[step 3750] loss=0.5195 lr=3.00e-04
[2025-08-30 19:46:13,073] [INFO] [logging.py:107:log_dist] [Rank 0] step=950, skipped=0, lr=[0.0002996060118564783], mom=[[0.9, 0.95]]
[2025-08-30 19:46:13,074] [INFO] [timer.py:264:stop] epoch=0/micro_step=3800/global_step=950, RunningAvgSamplesPerSec=4.204548184146679, CurrSamplesPerSec=4.2202484794330255, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 3800] loss=0.7539 lr=3.00e-04
[step 3850] loss=0.0003 lr=3.00e-04
[2025-08-30 19:49:24,651] [INFO] [logging.py:107:log_dist] [Rank 0] step=975, skipped=0, lr=[0.00029956104134195254], mom=[[0.9, 0.95]]
[2025-08-30 19:49:24,652] [INFO] [timer.py:264:stop] epoch=0/micro_step=3900/global_step=975, RunningAvgSamplesPerSec=4.204495702308673, CurrSamplesPerSec=4.111036598836962, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 3900] loss=0.1689 lr=3.00e-04
[step 3950] loss=0.0405 lr=3.00e-04
[2025-08-30 19:52:36,403] [INFO] [logging.py:107:log_dist] [Rank 0] step=1000, skipped=0, lr=[0.00029951364486050945], mom=[[0.9, 0.95]]
[2025-08-30 19:52:36,403] [INFO] [timer.py:264:stop] epoch=0/micro_step=4000/global_step=1000, RunningAvgSamplesPerSec=4.204353051111921, CurrSamplesPerSec=4.029175519738974, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 4000] loss=0.8438 lr=3.00e-04
[step 4050] loss=3.0469 lr=2.99e-04
[2025-08-30 19:55:48,195] [INFO] [logging.py:107:log_dist] [Rank 0] step=1025, skipped=0, lr=[0.0002994638231810246], mom=[[0.9, 0.95]]
[2025-08-30 19:55:48,199] [INFO] [timer.py:264:stop] epoch=0/micro_step=4100/global_step=1025, RunningAvgSamplesPerSec=4.204285668469724, CurrSamplesPerSec=4.21116548101579, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 4100] loss=0.5586 lr=2.99e-04
[step 4150] loss=0.6836 lr=2.99e-04
[2025-08-30 19:59:00,028] [INFO] [logging.py:107:log_dist] [Rank 0] step=1050, skipped=0, lr=[0.00029941157711171554], mom=[[0.9, 0.95]]
[2025-08-30 19:59:00,029] [INFO] [timer.py:264:stop] epoch=0/micro_step=4200/global_step=1050, RunningAvgSamplesPerSec=4.20410435783348, CurrSamplesPerSec=4.110367445918572, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 4200] loss=0.1738 lr=2.99e-04
[step 4250] loss=0.0918 lr=2.99e-04
[2025-08-30 20:02:11,676] [INFO] [logging.py:107:log_dist] [Rank 0] step=1075, skipped=0, lr=[0.00029935690750012894], mom=[[0.9, 0.95]]
[2025-08-30 20:02:11,677] [INFO] [timer.py:264:stop] epoch=0/micro_step=4300/global_step=1075, RunningAvgSamplesPerSec=4.204052601461813, CurrSamplesPerSec=4.096961826515971, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 4300] loss=0.1826 lr=2.99e-04
[step 4350] loss=0.1680 lr=2.99e-04
[2025-08-30 20:05:22,873] [INFO] [logging.py:107:log_dist] [Rank 0] step=1100, skipped=0, lr=[0.0002992998152331265], mom=[[0.9, 0.95]]
[2025-08-30 20:05:22,874] [INFO] [timer.py:264:stop] epoch=0/micro_step=4400/global_step=1100, RunningAvgSamplesPerSec=4.204225518848729, CurrSamplesPerSec=4.235099763881875, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 4400] loss=0.1191 lr=2.99e-04
[step 4450] loss=0.0530 lr=2.99e-04
[2025-08-30 20:08:33,889] [INFO] [logging.py:107:log_dist] [Rank 0] step=1125, skipped=0, lr=[0.00029924030123687083], mom=[[0.9, 0.95]]
[2025-08-30 20:08:33,890] [INFO] [timer.py:264:stop] epoch=0/micro_step=4500/global_step=1125, RunningAvgSamplesPerSec=4.204466822369941, CurrSamplesPerSec=4.239827666382792, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 4500] loss=0.0002 lr=2.99e-04
[step 4550] loss=0.1504 lr=2.99e-04
[2025-08-30 20:11:45,132] [INFO] [logging.py:107:log_dist] [Rank 0] step=1150, skipped=0, lr=[0.0002991783664768105], mom=[[0.9, 0.95]]
[2025-08-30 20:11:45,132] [INFO] [timer.py:264:stop] epoch=0/micro_step=4600/global_step=1150, RunningAvgSamplesPerSec=4.204585669764395, CurrSamplesPerSec=4.237012664713231, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 4600] loss=0.5664 lr=2.99e-04
[step 4650] loss=0.0116 lr=2.99e-04
[2025-08-30 20:14:56,178] [INFO] [logging.py:107:log_dist] [Rank 0] step=1175, skipped=0, lr=[0.00029911401195766376], mom=[[0.9, 0.95]]
[2025-08-30 20:14:56,179] [INFO] [timer.py:264:stop] epoch=0/micro_step=4700/global_step=1175, RunningAvgSamplesPerSec=4.204776331850021, CurrSamplesPerSec=4.21460678896304, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 4700] loss=0.3984 lr=2.99e-04
[step 4750] loss=0.0732 lr=2.99e-04
[2025-08-30 20:18:07,562] [INFO] [logging.py:107:log_dist] [Rank 0] step=1200, skipped=0, lr=[0.00029904723872340317], mom=[[0.9, 0.95]]
[2025-08-30 20:18:07,562] [INFO] [timer.py:264:stop] epoch=0/micro_step=4800/global_step=1200, RunningAvgSamplesPerSec=4.20483076222435, CurrSamplesPerSec=4.1954455290321695, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 4800] loss=0.9141 lr=2.99e-04
[step 4850] loss=0.9492 lr=2.99e-04
[2025-08-30 20:21:18,753] [INFO] [logging.py:107:log_dist] [Rank 0] step=1225, skipped=0, lr=[0.0002989780478572379], mom=[[0.9, 0.95]]
[2025-08-30 20:21:18,754] [INFO] [timer.py:264:stop] epoch=0/micro_step=4900/global_step=1225, RunningAvgSamplesPerSec=4.204947086602305, CurrSamplesPerSec=4.217225915124806, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 4900] loss=0.2871 lr=2.99e-04
[step 4950] loss=0.3125 lr=2.99e-04
[2025-08-30 20:24:30,039] [INFO] [logging.py:107:log_dist] [Rank 0] step=1250, skipped=0, lr=[0.0002989064404815966], mom=[[0.9, 0.95]]
[2025-08-30 20:24:30,040] [INFO] [timer.py:264:stop] epoch=0/micro_step=5000/global_step=1250, RunningAvgSamplesPerSec=4.2050270940127525, CurrSamplesPerSec=4.220559680467479, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 5000] loss=0.1738 lr=2.99e-04
[DeepSpeed] saving checkpoint step-5000 ...
[2025-08-30 20:24:30,049] [INFO] [logging.py:107:log_dist] [Rank 0] [Torch] Checkpoint step-5000 is begin to save!
[2025-08-30 20:24:30,087] [INFO] [logging.py:107:log_dist] [Rank 0] Saving model checkpoint: cosmopedia_v2_checkpoints/step-5000/zero_pp_rank_0_mp_rank_00_model_states.pt
[step 5050] loss=0.0084 lr=2.99e-04
[2025-08-30 20:27:42,336] [INFO] [logging.py:107:log_dist] [Rank 0] step=1275, skipped=0, lr=[0.00029883241775810894], mom=[[0.9, 0.95]]
[2025-08-30 20:27:42,337] [INFO] [timer.py:264:stop] epoch=0/micro_step=5100/global_step=1275, RunningAvgSamplesPerSec=4.205014621480493, CurrSamplesPerSec=4.214171951462465, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 5100] loss=0.0027 lr=2.99e-04
[step 5150] loss=0.1543 lr=2.99e-04
[2025-08-30 20:30:53,853] [INFO] [logging.py:107:log_dist] [Rank 0] step=1300, skipped=0, lr=[0.00029875598088758697], mom=[[0.9, 0.95]]
[2025-08-30 20:30:53,853] [INFO] [timer.py:264:stop] epoch=0/micro_step=5200/global_step=1300, RunningAvgSamplesPerSec=4.205010830141634, CurrSamplesPerSec=4.229303442794785, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 5200] loss=0.0422 lr=2.99e-04
[step 5250] loss=0.0493 lr=2.99e-04
[2025-08-30 20:34:05,337] [INFO] [logging.py:107:log_dist] [Rank 0] step=1325, skipped=0, lr=[0.0002986771311100054], mom=[[0.9, 0.95]]
[2025-08-30 20:34:05,337] [INFO] [timer.py:264:stop] epoch=0/micro_step=5300/global_step=1325, RunningAvgSamplesPerSec=4.204996616189909, CurrSamplesPerSec=4.2309159409728405, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 5300] loss=0.0474 lr=2.99e-04
[step 5350] loss=0.1582 lr=2.99e-04
[2025-08-30 20:37:16,557] [INFO] [logging.py:107:log_dist] [Rank 0] step=1350, skipped=0, lr=[0.00029859586970448163], mom=[[0.9, 0.95]]
[2025-08-30 20:37:16,557] [INFO] [timer.py:264:stop] epoch=0/micro_step=5400/global_step=1350, RunningAvgSamplesPerSec=4.2051118571068455, CurrSamplesPerSec=4.2288886183597505, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 5400] loss=0.4473 lr=2.99e-04
[step 5450] loss=0.0654 lr=2.99e-04
[2025-08-30 20:40:28,222] [INFO] [logging.py:107:log_dist] [Rank 0] step=1375, skipped=0, lr=[0.00029851219798925516], mom=[[0.9, 0.95]]
[2025-08-30 20:40:28,223] [INFO] [timer.py:264:stop] epoch=0/micro_step=5500/global_step=1375, RunningAvgSamplesPerSec=4.205063366601472, CurrSamplesPerSec=4.215966797547108, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 5500] loss=0.1167 lr=2.99e-04
[step 5550] loss=0.1226 lr=2.98e-04
[2025-08-30 20:43:40,023] [INFO] [logging.py:107:log_dist] [Rank 0] step=1400, skipped=0, lr=[0.00029842611732166586], mom=[[0.9, 0.95]]
[2025-08-30 20:43:40,024] [INFO] [timer.py:264:stop] epoch=0/micro_step=5600/global_step=1400, RunningAvgSamplesPerSec=4.204967878152904, CurrSamplesPerSec=4.235569673634769, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 5600] loss=0.8750 lr=2.98e-04
[step 5650] loss=0.0011 lr=2.98e-04
[2025-08-30 20:46:51,081] [INFO] [logging.py:107:log_dist] [Rank 0] step=1425, skipped=0, lr=[0.00029833762909813223], mom=[[0.9, 0.95]]
[2025-08-30 20:46:51,082] [INFO] [timer.py:264:stop] epoch=0/micro_step=5700/global_step=1425, RunningAvgSamplesPerSec=4.205145484434988, CurrSamplesPerSec=4.14154112913684, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 5700] loss=0.2617 lr=2.98e-04
[step 5750] loss=0.4395 lr=2.98e-04
[2025-08-30 20:50:02,832] [INFO] [logging.py:107:log_dist] [Rank 0] step=1450, skipped=0, lr=[0.00029824673475412853], mom=[[0.9, 0.95]]
[2025-08-30 20:50:02,832] [INFO] [timer.py:264:stop] epoch=0/micro_step=5800/global_step=1450, RunningAvgSamplesPerSec=4.205041543087916, CurrSamplesPerSec=4.225035961704402, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 5800] loss=0.0962 lr=2.98e-04
[step 5850] loss=0.0903 lr=2.98e-04
[2025-08-30 20:53:14,515] [INFO] [logging.py:107:log_dist] [Rank 0] step=1475, skipped=0, lr=[0.00029815343576416174], mom=[[0.9, 0.95]]
[2025-08-30 20:53:14,516] [INFO] [timer.py:264:stop] epoch=0/micro_step=5900/global_step=1475, RunningAvgSamplesPerSec=4.204983853603856, CurrSamplesPerSec=4.151468474406409, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 5900] loss=0.0928 lr=2.98e-04
[step 5950] loss=0.0757 lr=2.98e-04
[2025-08-30 20:56:25,526] [INFO] [logging.py:107:log_dist] [Rank 0] step=1500, skipped=0, lr=[0.0002980577336417473], mom=[[0.9, 0.95]]
[2025-08-30 20:56:25,527] [INFO] [timer.py:264:stop] epoch=0/micro_step=6000/global_step=1500, RunningAvgSamplesPerSec=4.205172757091111, CurrSamplesPerSec=4.148489739451821, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 6000] loss=0.2021 lr=2.98e-04
[step 6050] loss=0.4609 lr=2.98e-04
[2025-08-30 20:59:37,146] [INFO] [logging.py:107:log_dist] [Rank 0] step=1525, skipped=0, lr=[0.0002979596299393851], mom=[[0.9, 0.95]]
[2025-08-30 20:59:37,149] [INFO] [timer.py:264:stop] epoch=0/micro_step=6100/global_step=1525, RunningAvgSamplesPerSec=4.205170954443787, CurrSamplesPerSec=4.220310848670923, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 6100] loss=0.8789 lr=2.98e-04
[step 6150] loss=0.2734 lr=2.98e-04
[2025-08-30 21:02:48,325] [INFO] [logging.py:107:log_dist] [Rank 0] step=1550, skipped=0, lr=[0.00029785912624853364], mom=[[0.9, 0.95]]
[2025-08-30 21:02:48,326] [INFO] [timer.py:264:stop] epoch=0/micro_step=6200/global_step=1550, RunningAvgSamplesPerSec=4.205266486920561, CurrSamplesPerSec=4.2105815564077265, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 6200] loss=0.2051 lr=2.98e-04
[step 6250] loss=0.0374 lr=2.98e-04
[2025-08-30 21:05:59,743] [INFO] [logging.py:107:log_dist] [Rank 0] step=1575, skipped=0, lr=[0.0002977562241995846], mom=[[0.9, 0.95]]
[2025-08-30 21:05:59,744] [INFO] [timer.py:264:stop] epoch=0/micro_step=6300/global_step=1575, RunningAvgSamplesPerSec=4.2052714341176, CurrSamplesPerSec=4.222895749860468, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 6300] loss=0.2070 lr=2.98e-04
[step 6350] loss=0.3477 lr=2.98e-04
[2025-08-30 21:09:10,811] [INFO] [logging.py:107:log_dist] [Rank 0] step=1600, skipped=0, lr=[0.00029765092546183656], mom=[[0.9, 0.95]]
[2025-08-30 21:09:10,812] [INFO] [timer.py:264:stop] epoch=0/micro_step=6400/global_step=1600, RunningAvgSamplesPerSec=4.205420488498359, CurrSamplesPerSec=4.186453197394779, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 6400] loss=0.5156 lr=2.98e-04
[step 6450] loss=0.0000 lr=2.98e-04
[2025-08-30 21:12:21,575] [INFO] [logging.py:107:log_dist] [Rank 0] step=1625, skipped=0, lr=[0.0002975432317434673], mom=[[0.9, 0.95]]
[2025-08-30 21:12:21,575] [INFO] [timer.py:264:stop] epoch=0/micro_step=6500/global_step=1625, RunningAvgSamplesPerSec=4.205645787113455, CurrSamplesPerSec=4.225802312439922, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 6500] loss=0.0247 lr=2.98e-04
[step 6550] loss=0.8047 lr=2.97e-04
[2025-08-30 21:15:33,025] [INFO] [logging.py:107:log_dist] [Rank 0] step=1650, skipped=0, lr=[0.0002974331447915068], mom=[[0.9, 0.95]]
[2025-08-30 21:15:33,026] [INFO] [timer.py:264:stop] epoch=0/micro_step=6600/global_step=1650, RunningAvgSamplesPerSec=4.205679364214149, CurrSamplesPerSec=4.1430077132490375, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 6600] loss=0.0625 lr=2.97e-04
[step 6650] loss=0.1504 lr=2.97e-04
[2025-08-30 21:18:44,966] [INFO] [logging.py:107:log_dist] [Rank 0] step=1675, skipped=0, lr=[0.0002973206663918083], mom=[[0.9, 0.95]]
[2025-08-30 21:18:44,967] [INFO] [timer.py:264:stop] epoch=0/micro_step=6700/global_step=1675, RunningAvgSamplesPerSec=4.205562936137543, CurrSamplesPerSec=4.225327650367701, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 6700] loss=0.0047 lr=2.97e-04
[step 6750] loss=0.3145 lr=2.97e-04
[2025-08-30 21:21:56,437] [INFO] [logging.py:107:log_dist] [Rank 0] step=1700, skipped=0, lr=[0.0002972057983690199], mom=[[0.9, 0.95]]
[2025-08-30 21:21:56,438] [INFO] [timer.py:264:stop] epoch=0/micro_step=6800/global_step=1700, RunningAvgSamplesPerSec=4.205614211721161, CurrSamplesPerSec=4.216966346883327, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 6800] loss=0.2178 lr=2.97e-04
[step 6850] loss=0.0347 lr=2.97e-04
[2025-08-30 21:25:07,683] [INFO] [logging.py:107:log_dist] [Rank 0] step=1725, skipped=0, lr=[0.0002970885425865544], mom=[[0.9, 0.95]]
[2025-08-30 21:25:07,683] [INFO] [timer.py:264:stop] epoch=0/micro_step=6900/global_step=1725, RunningAvgSamplesPerSec=4.205648756054946, CurrSamplesPerSec=4.228828393629923, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 6900] loss=0.0000 lr=2.97e-04
[step 6950] loss=0.0145 lr=2.97e-04
[2025-08-30 21:28:18,943] [INFO] [logging.py:107:log_dist] [Rank 0] step=1750, skipped=0, lr=[0.0002969689009465595], mom=[[0.9, 0.95]]
[2025-08-30 21:28:18,943] [INFO] [timer.py:264:stop] epoch=0/micro_step=7000/global_step=1750, RunningAvgSamplesPerSec=4.2057162588126715, CurrSamplesPerSec=4.206510215475827, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 7000] loss=0.0454 lr=2.97e-04
[step 7050] loss=0.0986 lr=2.97e-04
[2025-08-30 21:31:30,716] [INFO] [logging.py:107:log_dist] [Rank 0] step=1775, skipped=0, lr=[0.0002968468753898867], mom=[[0.9, 0.95]]
[2025-08-30 21:31:30,717] [INFO] [timer.py:264:stop] epoch=0/micro_step=7100/global_step=1775, RunningAvgSamplesPerSec=4.205659679789509, CurrSamplesPerSec=4.2379967941528, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 7100] loss=0.0000 lr=2.97e-04
[step 7150] loss=0.0337 lr=2.97e-04
[2025-08-30 21:34:41,847] [INFO] [logging.py:107:log_dist] [Rank 0] step=1800, skipped=0, lr=[0.0002967224678960598], mom=[[0.9, 0.95]]
[2025-08-30 21:34:41,848] [INFO] [timer.py:264:stop] epoch=0/micro_step=7200/global_step=1800, RunningAvgSamplesPerSec=4.205729187744551, CurrSamplesPerSec=4.2132747707315605, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 7200] loss=0.0000 lr=2.97e-04
[step 7250] loss=0.3555 lr=2.97e-04
[2025-08-30 21:37:53,048] [INFO] [logging.py:107:log_dist] [Rank 0] step=1825, skipped=0, lr=[0.00029659568048324313], mom=[[0.9, 0.95]]
[2025-08-30 21:37:53,049] [INFO] [timer.py:264:stop] epoch=0/micro_step=7300/global_step=1825, RunningAvgSamplesPerSec=4.205746908029329, CurrSamplesPerSec=4.205869985488614, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 7300] loss=0.0067 lr=2.97e-04
[step 7350] loss=0.2402 lr=2.97e-04
[2025-08-30 21:41:03,943] [INFO] [logging.py:107:log_dist] [Rank 0] step=1850, skipped=0, lr=[0.00029646651520820835], mom=[[0.9, 0.95]]
[2025-08-30 21:41:03,944] [INFO] [timer.py:264:stop] epoch=0/micro_step=7400/global_step=1850, RunningAvgSamplesPerSec=4.2059124813194435, CurrSamplesPerSec=4.211606966812117, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 7400] loss=0.2090 lr=2.96e-04
[step 7450] loss=0.0000 lr=2.96e-04
[2025-08-30 21:44:15,189] [INFO] [logging.py:107:log_dist] [Rank 0] step=1875, skipped=0, lr=[0.0002963349741663014], mom=[[0.9, 0.95]]
[2025-08-30 21:44:15,190] [INFO] [timer.py:264:stop] epoch=0/micro_step=7500/global_step=1875, RunningAvgSamplesPerSec=4.2059343689281405, CurrSamplesPerSec=4.2266839395773115, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 7500] loss=0.0732 lr=2.96e-04
[step 7550] loss=0.2354 lr=2.96e-04
[2025-08-30 21:47:26,236] [INFO] [logging.py:107:log_dist] [Rank 0] step=1900, skipped=0, lr=[0.0002962010594914082], mom=[[0.9, 0.95]]
[2025-08-30 21:47:26,237] [INFO] [timer.py:264:stop] epoch=0/micro_step=7600/global_step=1900, RunningAvgSamplesPerSec=4.2060450426050116, CurrSamplesPerSec=4.207745749740168, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 7600] loss=0.0532 lr=2.96e-04
[step 7650] loss=0.0292 lr=2.96e-04
[2025-08-30 21:50:37,463] [INFO] [logging.py:107:log_dist] [Rank 0] step=1925, skipped=0, lr=[0.0002960647733559206], mom=[[0.9, 0.95]]
[2025-08-30 21:50:37,464] [INFO] [timer.py:264:stop] epoch=0/micro_step=7700/global_step=1925, RunningAvgSamplesPerSec=4.20606166028045, CurrSamplesPerSec=4.212725432852175, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 7700] loss=0.0422 lr=2.96e-04
[step 7750] loss=0.0894 lr=2.96e-04
[2025-08-30 21:53:48,644] [INFO] [logging.py:107:log_dist] [Rank 0] step=1950, skipped=0, lr=[0.0002959261179707005], mom=[[0.9, 0.95]]
[2025-08-30 21:53:48,645] [INFO] [timer.py:264:stop] epoch=0/micro_step=7800/global_step=1950, RunningAvgSamplesPerSec=4.206076560865688, CurrSamplesPerSec=4.2175174540531835, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 7800] loss=0.1152 lr=2.96e-04
[step 7850] loss=0.7344 lr=2.96e-04
[2025-08-30 21:56:59,792] [INFO] [logging.py:107:log_dist] [Rank 0] step=1975, skipped=0, lr=[0.0002957850955850443], mom=[[0.9, 0.95]]
[2025-08-30 21:56:59,793] [INFO] [timer.py:264:stop] epoch=0/micro_step=7900/global_step=1975, RunningAvgSamplesPerSec=4.206124789487518, CurrSamplesPerSec=4.229373943055053, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 7900] loss=0.0337 lr=2.96e-04
[step 7950] loss=0.2002 lr=2.96e-04
[2025-08-30 22:00:10,585] [INFO] [logging.py:107:log_dist] [Rank 0] step=2000, skipped=0, lr=[0.0002956417084866464], mom=[[0.9, 0.95]]
[2025-08-30 22:00:10,586] [INFO] [timer.py:264:stop] epoch=0/micro_step=8000/global_step=2000, RunningAvgSamplesPerSec=4.2062625155144096, CurrSamplesPerSec=4.1296191688709465, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 8000] loss=0.2734 lr=2.96e-04
[step 8050] loss=0.0089 lr=2.96e-04
[2025-08-30 22:03:21,089] [INFO] [logging.py:107:log_dist] [Rank 0] step=2025, skipped=0, lr=[0.0002954959590015621], mom=[[0.9, 0.95]]
[2025-08-30 22:03:21,090] [INFO] [timer.py:264:stop] epoch=0/micro_step=8100/global_step=2025, RunningAvgSamplesPerSec=4.206476164531768, CurrSamplesPerSec=4.17920932354864, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 8100] loss=0.0845 lr=2.95e-04
[step 8150] loss=0.0796 lr=2.95e-04
[2025-08-30 22:06:31,871] [INFO] [logging.py:107:log_dist] [Rank 0] step=2050, skipped=0, lr=[0.00029534784949416984], mom=[[0.9, 0.95]]
[2025-08-30 22:06:31,873] [INFO] [timer.py:264:stop] epoch=0/micro_step=8200/global_step=2050, RunningAvgSamplesPerSec=4.206627090687807, CurrSamplesPerSec=4.235197452687991, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 8200] loss=0.0280 lr=2.95e-04
[step 8250] loss=0.0000 lr=2.95e-04
[2025-08-30 22:09:43,053] [INFO] [logging.py:107:log_dist] [Rank 0] step=2075, skipped=0, lr=[0.00029519738236713267], mom=[[0.9, 0.95]]
[2025-08-30 22:09:43,054] [INFO] [timer.py:264:stop] epoch=0/micro_step=8300/global_step=2075, RunningAvgSamplesPerSec=4.206655645899421, CurrSamplesPerSec=4.2123028813660435, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 8300] loss=0.0270 lr=2.95e-04
[step 8350] loss=0.0757 lr=2.95e-04
[2025-08-30 22:12:53,903] [INFO] [logging.py:107:log_dist] [Rank 0] step=2100, skipped=0, lr=[0.00029504456006135965], mom=[[0.9, 0.95]]
[2025-08-30 22:12:53,904] [INFO] [timer.py:264:stop] epoch=0/micro_step=8400/global_step=2100, RunningAvgSamplesPerSec=4.206796249330702, CurrSamplesPerSec=4.144243840381503, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 8400] loss=0.0089 lr=2.95e-04
[step 8450] loss=0.0000 lr=2.95e-04
[2025-08-30 22:16:04,952] [INFO] [logging.py:107:log_dist] [Rank 0] step=2125, skipped=0, lr=[0.0002948893850559659], mom=[[0.9, 0.95]]
[2025-08-30 22:16:04,953] [INFO] [timer.py:264:stop] epoch=0/micro_step=8500/global_step=2125, RunningAvgSamplesPerSec=4.206865281868864, CurrSamplesPerSec=4.211184507528114, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 8500] loss=0.0439 lr=2.95e-04
[step 8550] loss=0.1777 lr=2.95e-04
[2025-08-30 22:19:16,111] [INFO] [logging.py:107:log_dist] [Rank 0] step=2150, skipped=0, lr=[0.00029473185986823256], mom=[[0.9, 0.95]]
[2025-08-30 22:19:16,112] [INFO] [timer.py:264:stop] epoch=0/micro_step=8600/global_step=2150, RunningAvgSamplesPerSec=4.206898185700364, CurrSamplesPerSec=4.231248459095883, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 8600] loss=0.1445 lr=2.95e-04
[step 8650] loss=0.0269 lr=2.95e-04
[2025-08-30 22:22:27,730] [INFO] [logging.py:107:log_dist] [Rank 0] step=2175, skipped=0, lr=[0.00029457198705356587], mom=[[0.9, 0.95]]
[2025-08-30 22:22:27,731] [INFO] [timer.py:264:stop] epoch=0/micro_step=8700/global_step=2175, RunningAvgSamplesPerSec=4.206793466518689, CurrSamplesPerSec=4.054820923306759, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 8700] loss=0.0400 lr=2.95e-04
[step 8750] loss=0.0105 lr=2.94e-04
[2025-08-30 22:25:38,622] [INFO] [logging.py:107:log_dist] [Rank 0] step=2200, skipped=0, lr=[0.00029440976920545593], mom=[[0.9, 0.95]]
[2025-08-30 22:25:38,622] [INFO] [timer.py:264:stop] epoch=0/micro_step=8800/global_step=2200, RunningAvgSamplesPerSec=4.206902003357185, CurrSamplesPerSec=4.205646603352555, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 8800] loss=0.0228 lr=2.94e-04
[step 8850] loss=0.1592 lr=2.94e-04
[2025-08-30 22:28:49,688] [INFO] [logging.py:107:log_dist] [Rank 0] step=2225, skipped=0, lr=[0.0002942452089554343], mom=[[0.9, 0.95]]
[2025-08-30 22:28:49,689] [INFO] [timer.py:264:stop] epoch=0/micro_step=8900/global_step=2225, RunningAvgSamplesPerSec=4.20695254862652, CurrSamplesPerSec=4.209793647050351, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 8900] loss=0.0337 lr=2.94e-04
[step 8950] loss=0.0000 lr=2.94e-04
[2025-08-30 22:32:00,257] [INFO] [logging.py:107:log_dist] [Rank 0] step=2250, skipped=0, lr=[0.0002940783089730313], mom=[[0.9, 0.95]]
[2025-08-30 22:32:00,258] [INFO] [timer.py:264:stop] epoch=0/micro_step=9000/global_step=2250, RunningAvgSamplesPerSec=4.207106459125134, CurrSamplesPerSec=4.222232990033425, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 9000] loss=0.2021 lr=2.94e-04
[step 9050] loss=0.0306 lr=2.94e-04
[2025-08-30 22:35:11,365] [INFO] [logging.py:107:log_dist] [Rank 0] step=2275, skipped=0, lr=[0.0002939090719657334], mom=[[0.9, 0.95]]
[2025-08-30 22:35:11,365] [INFO] [timer.py:264:stop] epoch=0/micro_step=9100/global_step=2275, RunningAvgSamplesPerSec=4.207164473910344, CurrSamplesPerSec=4.227311482907727, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 9100] loss=0.0019 lr=2.94e-04
[step 9150] loss=0.1299 lr=2.94e-04
[2025-08-30 22:38:22,075] [INFO] [logging.py:107:log_dist] [Rank 0] step=2300, skipped=0, lr=[0.0002937375006789383], mom=[[0.9, 0.95]]
[2025-08-30 22:38:22,076] [INFO] [timer.py:264:stop] epoch=0/micro_step=9200/global_step=2300, RunningAvgSamplesPerSec=4.207300608184197, CurrSamplesPerSec=4.158486282633864, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 9200] loss=0.1621 lr=2.94e-04
[step 9250] loss=0.0967 lr=2.94e-04
[2025-08-30 22:41:33,323] [INFO] [logging.py:107:log_dist] [Rank 0] step=2325, skipped=0, lr=[0.000293563597895911], mom=[[0.9, 0.95]]
[2025-08-30 22:41:33,324] [INFO] [timer.py:264:stop] epoch=0/micro_step=9300/global_step=2325, RunningAvgSamplesPerSec=4.207300731451914, CurrSamplesPerSec=4.19157774618526, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 9300] loss=0.0640 lr=2.94e-04
[step 9350] loss=0.0018 lr=2.93e-04
[2025-08-30 22:44:44,085] [INFO] [logging.py:107:log_dist] [Rank 0] step=2350, skipped=0, lr=[0.0002933873664377385], mom=[[0.9, 0.95]]
[2025-08-30 22:44:44,085] [INFO] [timer.py:264:stop] epoch=0/micro_step=9400/global_step=2350, RunningAvgSamplesPerSec=4.207414065696062, CurrSamplesPerSec=4.219105325804125, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 9400] loss=0.0000 lr=2.93e-04
[step 9450] loss=0.0129 lr=2.93e-04
[2025-08-30 22:47:54,680] [INFO] [logging.py:107:log_dist] [Rank 0] step=2375, skipped=0, lr=[0.00029320880916328416], mom=[[0.9, 0.95]]
[2025-08-30 22:47:54,680] [INFO] [timer.py:264:stop] epoch=0/micro_step=9500/global_step=2375, RunningAvgSamplesPerSec=4.207553990785234, CurrSamplesPerSec=4.222060061083971, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 9500] loss=0.0723 lr=2.93e-04
[step 9550] loss=0.2715 lr=2.93e-04
[2025-08-30 22:51:05,526] [INFO] [logging.py:107:log_dist] [Rank 0] step=2400, skipped=0, lr=[0.0002930279289691412], mom=[[0.9, 0.95]]
[2025-08-30 22:51:05,528] [INFO] [timer.py:264:stop] epoch=0/micro_step=9600/global_step=2400, RunningAvgSamplesPerSec=4.207646687319485, CurrSamplesPerSec=4.229749406523296, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 9600] loss=0.0123 lr=2.93e-04
[step 9650] loss=0.0001 lr=2.93e-04
[2025-08-30 22:54:16,374] [INFO] [logging.py:107:log_dist] [Rank 0] step=2425, skipped=0, lr=[0.00029284472878958554], mom=[[0.9, 0.95]]
[2025-08-30 22:54:16,375] [INFO] [timer.py:264:stop] epoch=0/micro_step=9700/global_step=2425, RunningAvgSamplesPerSec=4.207740394528815, CurrSamplesPerSec=4.211994615057674, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 9700] loss=0.0092 lr=2.93e-04
[step 9750] loss=0.0000 lr=2.93e-04
[2025-08-30 22:57:27,429] [INFO] [logging.py:107:log_dist] [Rank 0] step=2450, skipped=0, lr=[0.0002926592115965286], mom=[[0.9, 0.95]]
[2025-08-30 22:57:27,430] [INFO] [timer.py:264:stop] epoch=0/micro_step=9800/global_step=2450, RunningAvgSamplesPerSec=4.207793356414543, CurrSamplesPerSec=4.238402700057334, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 9800] loss=0.1943 lr=2.93e-04
[step 9850] loss=0.0576 lr=2.93e-04
[2025-08-30 23:00:38,772] [INFO] [logging.py:107:log_dist] [Rank 0] step=2475, skipped=0, lr=[0.0002924713803994687], mom=[[0.9, 0.95]]
[2025-08-30 23:00:38,773] [INFO] [timer.py:264:stop] epoch=0/micro_step=9900/global_step=2475, RunningAvgSamplesPerSec=4.207761630703329, CurrSamplesPerSec=4.164467775475575, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 9900] loss=0.0150 lr=2.92e-04
[step 9950] loss=0.0728 lr=2.92e-04
[2025-08-30 23:03:49,260] [INFO] [logging.py:107:log_dist] [Rank 0] step=2500, skipped=0, lr=[0.00029228123824544256], mom=[[0.9, 0.95]]
[2025-08-30 23:03:49,260] [INFO] [timer.py:264:stop] epoch=0/micro_step=10000/global_step=2500, RunningAvgSamplesPerSec=4.207922838722386, CurrSamplesPerSec=4.233134250202627, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 10000] loss=0.0178 lr=2.92e-04
[DeepSpeed] saving checkpoint step-10000 ...
[2025-08-30 23:03:49,269] [INFO] [logging.py:107:log_dist] [Rank 0] [Torch] Checkpoint step-10000 is begin to save!
[2025-08-30 23:03:49,292] [INFO] [logging.py:107:log_dist] [Rank 0] Saving model checkpoint: cosmopedia_v2_checkpoints/step-10000/zero_pp_rank_0_mp_rank_00_model_states.pt
[step 10050] loss=0.0703 lr=2.92e-04
[2025-08-30 23:07:00,950] [INFO] [logging.py:107:log_dist] [Rank 0] step=2525, skipped=0, lr=[0.00029208878821897574], mom=[[0.9, 0.95]]
[2025-08-30 23:07:00,951] [INFO] [timer.py:264:stop] epoch=0/micro_step=10100/global_step=2525, RunningAvgSamplesPerSec=4.2079893459445055, CurrSamplesPerSec=4.215681299049742, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 10100] loss=0.0000 lr=2.92e-04
[step 10150] loss=0.0000 lr=2.92e-04
[2025-08-30 23:10:11,913] [INFO] [logging.py:107:log_dist] [Rank 0] step=2550, skipped=0, lr=[0.00029189403344203235], mom=[[0.9, 0.95]]
[2025-08-30 23:10:11,915] [INFO] [timer.py:264:stop] epoch=0/micro_step=10200/global_step=2550, RunningAvgSamplesPerSec=4.208013237794054, CurrSamplesPerSec=4.225510425210486, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 10200] loss=1.2031 lr=2.92e-04
[step 10250] loss=0.0000 lr=2.92e-04
[2025-08-30 23:13:23,384] [INFO] [logging.py:107:log_dist] [Rank 0] step=2575, skipped=0, lr=[0.00029169697707396485], mom=[[0.9, 0.95]]
[2025-08-30 23:13:23,388] [INFO] [timer.py:264:stop] epoch=0/micro_step=10300/global_step=2575, RunningAvgSamplesPerSec=4.207956429713972, CurrSamplesPerSec=4.22092654522687, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 10300] loss=0.0000 lr=2.92e-04
[step 10350] loss=0.0006 lr=2.92e-04
[2025-08-30 23:16:34,146] [INFO] [logging.py:107:log_dist] [Rank 0] step=2600, skipped=0, lr=[0.00029149762231146255], mom=[[0.9, 0.95]]
[2025-08-30 23:16:34,147] [INFO] [timer.py:264:stop] epoch=0/micro_step=10400/global_step=2600, RunningAvgSamplesPerSec=4.208033830256079, CurrSamplesPerSec=4.2073583555907295, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 10400] loss=0.0449 lr=2.91e-04
[step 10450] loss=0.0000 lr=2.91e-04
[2025-08-30 23:19:45,172] [INFO] [logging.py:107:log_dist] [Rank 0] step=2625, skipped=0, lr=[0.00029129597238849986], mom=[[0.9, 0.95]]
[2025-08-30 23:19:45,173] [INFO] [timer.py:264:stop] epoch=0/micro_step=10500/global_step=2625, RunningAvgSamplesPerSec=4.208067781951849, CurrSamplesPerSec=4.200771981877884, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 10500] loss=0.0000 lr=2.91e-04
[step 10550] loss=0.0618 lr=2.91e-04
[2025-08-30 23:22:56,558] [INFO] [logging.py:107:log_dist] [Rank 0] step=2650, skipped=0, lr=[0.00029109203057628354], mom=[[0.9, 0.95]]
[2025-08-30 23:22:56,559] [INFO] [timer.py:264:stop] epoch=0/micro_step=10600/global_step=2650, RunningAvgSamplesPerSec=4.208014956271037, CurrSamplesPerSec=4.219138084844921, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 10600] loss=0.0004 lr=2.91e-04
[step 10650] loss=0.0120 lr=2.91e-04
[2025-08-30 23:26:07,844] [INFO] [logging.py:107:log_dist] [Rank 0] step=2675, skipped=0, lr=[0.0002908858001832001], mom=[[0.9, 0.95]]
[2025-08-30 23:26:07,845] [INFO] [timer.py:264:stop] epoch=0/micro_step=10700/global_step=2675, RunningAvgSamplesPerSec=4.207977021167237, CurrSamplesPerSec=4.1871977765488095, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 10700] loss=0.1211 lr=2.91e-04
[step 10750] loss=0.0205 lr=2.91e-04
[2025-08-30 23:29:18,171] [INFO] [logging.py:107:log_dist] [Rank 0] step=2700, skipped=0, lr=[0.0002906772845547617], mom=[[0.9, 0.95]]
[2025-08-30 23:29:18,172] [INFO] [timer.py:264:stop] epoch=0/micro_step=10800/global_step=2700, RunningAvgSamplesPerSec=4.208149227210236, CurrSamplesPerSec=4.212076568249213, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 10800] loss=0.2236 lr=2.91e-04
[step 10850] loss=0.0078 lr=2.91e-04
[2025-08-30 23:32:29,381] [INFO] [logging.py:107:log_dist] [Rank 0] step=2725, skipped=0, lr=[0.0002904664870735521], mom=[[0.9, 0.95]]
[2025-08-30 23:32:29,382] [INFO] [timer.py:264:stop] epoch=0/micro_step=10900/global_step=2725, RunningAvgSamplesPerSec=4.208128475757819, CurrSamplesPerSec=4.220555300774191, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 10900] loss=0.0277 lr=2.90e-04
[step 10950] loss=0.0070 lr=2.90e-04
[2025-08-30 23:35:40,161] [INFO] [logging.py:107:log_dist] [Rank 0] step=2750, skipped=0, lr=[0.00029025341115917195], mom=[[0.9, 0.95]]
[2025-08-30 23:35:40,162] [INFO] [timer.py:264:stop] epoch=0/micro_step=11000/global_step=2750, RunningAvgSamplesPerSec=4.208214212166897, CurrSamplesPerSec=4.228359845199864, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 11000] loss=0.1074 lr=2.90e-04
[step 11050] loss=0.1357 lr=2.90e-04
[2025-08-30 23:38:51,167] [INFO] [logging.py:107:log_dist] [Rank 0] step=2775, skipped=0, lr=[0.00029003806026818275], mom=[[0.9, 0.95]]
[2025-08-30 23:38:51,168] [INFO] [timer.py:264:stop] epoch=0/micro_step=11100/global_step=2775, RunningAvgSamplesPerSec=4.208251973876921, CurrSamplesPerSec=4.222317600217858, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 11100] loss=0.2031 lr=2.90e-04
[step 11150] loss=0.0000 lr=2.90e-04
[2025-08-30 23:42:02,119] [INFO] [logging.py:107:log_dist] [Rank 0] step=2800, skipped=0, lr=[0.00028982043789405157], mom=[[0.9, 0.95]]
[2025-08-30 23:42:02,120] [INFO] [timer.py:264:stop] epoch=0/micro_step=11200/global_step=2800, RunningAvgSamplesPerSec=4.208282660729924, CurrSamplesPerSec=4.241892439935477, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 11200] loss=0.0160 lr=2.90e-04
[step 11250] loss=0.0306 lr=2.90e-04
[2025-08-30 23:45:13,947] [INFO] [logging.py:107:log_dist] [Rank 0] step=2825, skipped=0, lr=[0.00028960054756709355], mom=[[0.9, 0.95]]
[2025-08-30 23:45:13,948] [INFO] [timer.py:264:stop] epoch=0/micro_step=11300/global_step=2825, RunningAvgSamplesPerSec=4.208140932860843, CurrSamplesPerSec=4.214772225451013, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 11300] loss=0.1406 lr=2.90e-04
[step 11350] loss=0.0136 lr=2.89e-04
[2025-08-30 23:48:25,355] [INFO] [logging.py:107:log_dist] [Rank 0] step=2850, skipped=0, lr=[0.0002893783928544152], mom=[[0.9, 0.95]]
[2025-08-30 23:48:25,355] [INFO] [timer.py:264:stop] epoch=0/micro_step=11400/global_step=2850, RunningAvgSamplesPerSec=4.208091129523029, CurrSamplesPerSec=4.210502963538517, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 11400] loss=0.0000 lr=2.89e-04
[step 11450] loss=0.0364 lr=2.89e-04
[2025-08-30 23:51:37,061] [INFO] [logging.py:107:log_dist] [Rank 0] step=2875, skipped=0, lr=[0.0002891539773598565], mom=[[0.9, 0.95]]
[2025-08-30 23:51:37,062] [INFO] [timer.py:264:stop] epoch=0/micro_step=11500/global_step=2875, RunningAvgSamplesPerSec=4.207980751567132, CurrSamplesPerSec=4.231199905256998, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 11500] loss=0.0000 lr=2.89e-04
[step 11550] loss=0.0688 lr=2.89e-04
[2025-08-30 23:54:48,040] [INFO] [logging.py:107:log_dist] [Rank 0] step=2900, skipped=0, lr=[0.0002889273047239321], mom=[[0.9, 0.95]]
[2025-08-30 23:54:48,041] [INFO] [timer.py:264:stop] epoch=0/micro_step=11600/global_step=2900, RunningAvgSamplesPerSec=4.208005867841, CurrSamplesPerSec=4.212150725417706, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 11600] loss=0.0317 lr=2.89e-04
[step 11650] loss=0.0000 lr=2.89e-04
[2025-08-30 23:57:59,151] [INFO] [logging.py:107:log_dist] [Rank 0] step=2925, skipped=0, lr=[0.0002886983786237725], mom=[[0.9, 0.95]]
[2025-08-30 23:57:59,152] [INFO] [timer.py:264:stop] epoch=0/micro_step=11700/global_step=2925, RunningAvgSamplesPerSec=4.208003559671302, CurrSamplesPerSec=4.219276951690775, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 11700] loss=0.0066 lr=2.89e-04
[step 11750] loss=0.0461 lr=2.89e-04
[2025-08-31 00:01:10,049] [INFO] [logging.py:107:log_dist] [Rank 0] step=2950, skipped=0, lr=[0.0002884672027730645], mom=[[0.9, 0.95]]
[2025-08-31 00:01:10,050] [INFO] [timer.py:264:stop] epoch=0/micro_step=11800/global_step=2950, RunningAvgSamplesPerSec=4.208057625741161, CurrSamplesPerSec=4.201969022540418, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 11800] loss=0.0047 lr=2.88e-04
[step 11850] loss=0.0972 lr=2.88e-04
[2025-08-31 00:04:20,920] [INFO] [logging.py:107:log_dist] [Rank 0] step=2975, skipped=0, lr=[0.0002882337809219907], mom=[[0.9, 0.95]]
[2025-08-31 00:04:20,921] [INFO] [timer.py:264:stop] epoch=0/micro_step=11900/global_step=2975, RunningAvgSamplesPerSec=4.208100373938145, CurrSamplesPerSec=4.222355191073758, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 11900] loss=0.0398 lr=2.88e-04
[step 11950] loss=0.0017 lr=2.88e-04
[2025-08-31 00:07:32,001] [INFO] [logging.py:107:log_dist] [Rank 0] step=3000, skipped=0, lr=[0.0002879981168571687], mom=[[0.9, 0.95]]
[2025-08-31 00:07:32,002] [INFO] [timer.py:264:stop] epoch=0/micro_step=12000/global_step=3000, RunningAvgSamplesPerSec=4.208102490137681, CurrSamplesPerSec=4.226589038871385, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 12000] loss=0.0359 lr=2.88e-04
[step 12050] loss=0.0045 lr=2.88e-04
[2025-08-31 00:10:43,661] [INFO] [logging.py:107:log_dist] [Rank 0] step=3025, skipped=0, lr=[0.00028776021440159004], mom=[[0.9, 0.95]]
[2025-08-31 00:10:43,662] [INFO] [timer.py:264:stop] epoch=0/micro_step=12100/global_step=3025, RunningAvgSamplesPerSec=4.208022894048811, CurrSamplesPerSec=4.213503990395839, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 12100] loss=0.0674 lr=2.88e-04
[step 12150] loss=0.0312 lr=2.88e-04
[2025-08-31 00:13:54,501] [INFO] [logging.py:107:log_dist] [Rank 0] step=3050, skipped=0, lr=[0.0002875200774145576], mom=[[0.9, 0.95]]
[2025-08-31 00:13:54,501] [INFO] [timer.py:264:stop] epoch=0/micro_step=12200/global_step=3050, RunningAvgSamplesPerSec=4.208069125338016, CurrSamplesPerSec=4.230198797435018, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 12200] loss=0.0303 lr=2.88e-04
[step 12250] loss=0.0000 lr=2.87e-04
[2025-08-31 00:17:05,377] [INFO] [logging.py:107:log_dist] [Rank 0] step=3075, skipped=0, lr=[0.00028727770979162343], mom=[[0.9, 0.95]]
[2025-08-31 00:17:05,378] [INFO] [timer.py:264:stop] epoch=0/micro_step=12300/global_step=3075, RunningAvgSamplesPerSec=4.208108485278243, CurrSamplesPerSec=4.208849231281021, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 12300] loss=0.0728 lr=2.87e-04
[step 12350] loss=0.0496 lr=2.87e-04
[2025-08-31 00:20:16,610] [INFO] [logging.py:107:log_dist] [Rank 0] step=3100, skipped=0, lr=[0.0002870331154645255], mom=[[0.9, 0.95]]
[2025-08-31 00:20:16,615] [INFO] [timer.py:264:stop] epoch=0/micro_step=12400/global_step=3100, RunningAvgSamplesPerSec=4.2081162586174345, CurrSamplesPerSec=4.224326128132336, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 12400] loss=0.0212 lr=2.87e-04
[step 12450] loss=0.1689 lr=2.87e-04
[2025-08-31 00:23:27,506] [INFO] [logging.py:107:log_dist] [Rank 0] step=3125, skipped=0, lr=[0.0002867862984011236], mom=[[0.9, 0.95]]
[2025-08-31 00:23:27,506] [INFO] [timer.py:264:stop] epoch=0/micro_step=12500/global_step=3125, RunningAvgSamplesPerSec=4.208167770907709, CurrSamplesPerSec=4.218234148531318, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 12500] loss=0.0000 lr=2.87e-04
[step 12550] loss=0.0601 lr=2.87e-04
[2025-08-31 00:26:38,651] [INFO] [logging.py:107:log_dist] [Rank 0] step=3150, skipped=0, lr=[0.0002865372626053355], mom=[[0.9, 0.95]]
[2025-08-31 00:26:38,651] [INFO] [timer.py:264:stop] epoch=0/micro_step=12600/global_step=3150, RunningAvgSamplesPerSec=4.208171070212476, CurrSamplesPerSec=4.218959441516216, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 12600] loss=0.2432 lr=2.87e-04
[step 12650] loss=0.0083 lr=2.86e-04
[2025-08-31 00:29:49,691] [INFO] [logging.py:107:log_dist] [Rank 0] step=3175, skipped=0, lr=[0.0002862860121170714], mom=[[0.9, 0.95]]
[2025-08-31 00:29:49,691] [INFO] [timer.py:264:stop] epoch=0/micro_step=12700/global_step=3175, RunningAvgSamplesPerSec=4.208202238835532, CurrSamplesPerSec=4.21938293168008, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 12700] loss=0.0447 lr=2.86e-04
[step 12750] loss=0.0000 lr=2.86e-04
[2025-08-31 00:33:00,845] [INFO] [logging.py:107:log_dist] [Rank 0] step=3200, skipped=0, lr=[0.000286032551012169], mom=[[0.9, 0.95]]
[2025-08-31 00:33:00,846] [INFO] [timer.py:264:stop] epoch=0/micro_step=12800/global_step=3200, RunningAvgSamplesPerSec=4.208194256200287, CurrSamplesPerSec=4.2363589717201835, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 12800] loss=0.0000 lr=2.86e-04
[step 12850] loss=0.0060 lr=2.86e-04
[2025-08-31 00:36:12,268] [INFO] [logging.py:107:log_dist] [Rank 0] step=3225, skipped=0, lr=[0.00028577688340232694], mom=[[0.9, 0.95]]
[2025-08-31 00:36:12,269] [INFO] [timer.py:264:stop] epoch=0/micro_step=12900/global_step=3225, RunningAvgSamplesPerSec=4.208138939787412, CurrSamplesPerSec=4.217877030066808, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 12900] loss=0.0059 lr=2.86e-04
[step 12950] loss=0.2217 lr=2.86e-04
[2025-08-31 00:39:23,487] [INFO] [logging.py:107:log_dist] [Rank 0] step=3250, skipped=0, lr=[0.00028551901343503816], mom=[[0.9, 0.95]]
[2025-08-31 00:39:23,487] [INFO] [timer.py:264:stop] epoch=0/micro_step=13000/global_step=3250, RunningAvgSamplesPerSec=4.2081247500764585, CurrSamplesPerSec=4.182606400858064, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 13000] loss=0.0304 lr=2.86e-04
[step 13050] loss=0.0119 lr=2.85e-04
[2025-08-31 00:42:34,616] [INFO] [logging.py:107:log_dist] [Rank 0] step=3275, skipped=0, lr=[0.0002852589452935228], mom=[[0.9, 0.95]]
[2025-08-31 00:42:34,617] [INFO] [timer.py:264:stop] epoch=0/micro_step=13100/global_step=3275, RunningAvgSamplesPerSec=4.208142163760041, CurrSamplesPerSec=4.218361156236341, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 13100] loss=0.0226 lr=2.85e-04
[step 13150] loss=0.0255 lr=2.85e-04
[2025-08-31 00:45:45,492] [INFO] [logging.py:107:log_dist] [Rank 0] step=3300, skipped=0, lr=[0.0002849966831966603], mom=[[0.9, 0.95]]
[2025-08-31 00:45:45,493] [INFO] [timer.py:264:stop] epoch=0/micro_step=13200/global_step=3300, RunningAvgSamplesPerSec=4.208195801298678, CurrSamplesPerSec=4.227961720595044, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 13200] loss=0.0012 lr=2.85e-04
[step 13250] loss=0.0000 lr=2.85e-04
[2025-08-31 00:48:56,472] [INFO] [logging.py:107:log_dist] [Rank 0] step=3325, skipped=0, lr=[0.00028473223139892075], mom=[[0.9, 0.95]]
[2025-08-31 00:48:56,472] [INFO] [timer.py:264:stop] epoch=0/micro_step=13300/global_step=3325, RunningAvgSamplesPerSec=4.2082305228538015, CurrSamplesPerSec=4.22496494101341, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 13300] loss=0.0417 lr=2.85e-04
[step 13350] loss=0.0020 lr=2.85e-04
[2025-08-31 00:52:08,004] [INFO] [logging.py:107:log_dist] [Rank 0] step=3350, skipped=0, lr=[0.0002844655941902961], mom=[[0.9, 0.95]]
[2025-08-31 00:52:08,004] [INFO] [timer.py:264:stop] epoch=0/micro_step=13400/global_step=3350, RunningAvgSamplesPerSec=4.208188876107717, CurrSamplesPerSec=4.222105749076213, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 13400] loss=0.0057 lr=2.84e-04
[step 13450] loss=0.0135 lr=2.84e-04
[2025-08-31 00:55:18,843] [INFO] [logging.py:107:log_dist] [Rank 0] step=3375, skipped=0, lr=[0.00028419677589623047], mom=[[0.9, 0.95]]
[2025-08-31 00:55:18,844] [INFO] [timer.py:264:stop] epoch=0/micro_step=13500/global_step=3375, RunningAvgSamplesPerSec=4.20823036948252, CurrSamplesPerSec=4.245740322146357, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 13500] loss=0.0004 lr=2.84e-04
[step 13550] loss=0.0718 lr=2.84e-04
[2025-08-31 00:58:29,800] [INFO] [logging.py:107:log_dist] [Rank 0] step=3400, skipped=0, lr=[0.0002839257808775501], mom=[[0.9, 0.95]]
[2025-08-31 00:58:29,801] [INFO] [timer.py:264:stop] epoch=0/micro_step=13600/global_step=3400, RunningAvgSamplesPerSec=4.2082768220008315, CurrSamplesPerSec=4.2316781557770735, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 13600] loss=0.0000 lr=2.84e-04
[step 13650] loss=0.0049 lr=2.84e-04
[2025-08-31 01:01:40,594] [INFO] [logging.py:107:log_dist] [Rank 0] step=3425, skipped=0, lr=[0.0002836526135303923], mom=[[0.9, 0.95]]
[2025-08-31 01:01:40,595] [INFO] [timer.py:264:stop] epoch=0/micro_step=13700/global_step=3425, RunningAvgSamplesPerSec=4.208340991608734, CurrSamplesPerSec=4.230408794772771, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 13700] loss=0.0000 lr=2.84e-04
[step 13750] loss=0.0020 lr=2.84e-04
[2025-08-31 01:04:51,802] [INFO] [logging.py:107:log_dist] [Rank 0] step=3450, skipped=0, lr=[0.0002833772782861346], mom=[[0.9, 0.95]]
[2025-08-31 01:04:51,803] [INFO] [timer.py:264:stop] epoch=0/micro_step=13800/global_step=3450, RunningAvgSamplesPerSec=4.208328009561426, CurrSamplesPerSec=4.208653246167452, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 13800] loss=0.1138 lr=2.83e-04
[step 13850] loss=0.1094 lr=2.83e-04
[2025-08-31 01:08:02,606] [INFO] [logging.py:107:log_dist] [Rank 0] step=3475, skipped=0, lr=[0.0002830997796113223], mom=[[0.9, 0.95]]
[2025-08-31 01:08:02,607] [INFO] [timer.py:264:stop] epoch=0/micro_step=13900/global_step=3475, RunningAvgSamplesPerSec=4.208381117349614, CurrSamplesPerSec=4.21321036092356, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 13900] loss=0.0000 lr=2.83e-04
[step 13950] loss=0.0008 lr=2.83e-04
[2025-08-31 01:11:13,262] [INFO] [logging.py:107:log_dist] [Rank 0] step=3500, skipped=0, lr=[0.00028282012200759666], mom=[[0.9, 0.95]]
[2025-08-31 01:11:13,262] [INFO] [timer.py:264:stop] epoch=0/micro_step=14000/global_step=3500, RunningAvgSamplesPerSec=4.208447175961283, CurrSamplesPerSec=4.223824548108703, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 14000] loss=0.0001 lr=2.83e-04
[step 14050] loss=0.0243 lr=2.83e-04
[2025-08-31 01:14:24,535] [INFO] [logging.py:107:log_dist] [Rank 0] step=3525, skipped=0, lr=[0.0002825383100116213], mom=[[0.9, 0.95]]
[2025-08-31 01:14:24,536] [INFO] [timer.py:264:stop] epoch=0/micro_step=14100/global_step=3525, RunningAvgSamplesPerSec=4.208438536080968, CurrSamplesPerSec=4.203232954784229, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 14100] loss=0.0422 lr=2.83e-04
[step 14150] loss=0.0156 lr=2.82e-04
[2025-08-31 01:17:35,656] [INFO] [logging.py:107:log_dist] [Rank 0] step=3550, skipped=0, lr=[0.00028225434819500886], mom=[[0.9, 0.95]]
[2025-08-31 01:17:35,657] [INFO] [timer.py:264:stop] epoch=0/micro_step=14200/global_step=3550, RunningAvgSamplesPerSec=4.208435868896602, CurrSamplesPerSec=4.230644016545021, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 14200] loss=0.0006 lr=2.82e-04
[step 14250] loss=0.0000 lr=2.82e-04
[2025-08-31 01:20:46,705] [INFO] [logging.py:107:log_dist] [Rank 0] step=3575, skipped=0, lr=[0.00028196824116424684], mom=[[0.9, 0.95]]
[2025-08-31 01:20:46,708] [INFO] [timer.py:264:stop] epoch=0/micro_step=14300/global_step=3575, RunningAvgSamplesPerSec=4.208461683276461, CurrSamplesPerSec=4.240753075206417, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 14300] loss=0.0000 lr=2.82e-04
[step 14350] loss=0.0126 lr=2.82e-04
[2025-08-31 01:23:57,434] [INFO] [logging.py:107:log_dist] [Rank 0] step=3600, skipped=0, lr=[0.000281679993560623], mom=[[0.9, 0.95]]
[2025-08-31 01:23:57,440] [INFO] [timer.py:264:stop] epoch=0/micro_step=14400/global_step=3600, RunningAvgSamplesPerSec=4.208520261220899, CurrSamplesPerSec=4.147377820439969, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 14400] loss=0.0000 lr=2.82e-04
[step 14450] loss=0.0110 lr=2.82e-04
[2025-08-31 01:27:08,125] [INFO] [logging.py:107:log_dist] [Rank 0] step=3625, skipped=0, lr=[0.00028138961006014964], mom=[[0.9, 0.95]]
[2025-08-31 01:27:08,126] [INFO] [timer.py:264:stop] epoch=0/micro_step=14500/global_step=3625, RunningAvgSamplesPerSec=4.208583186077595, CurrSamplesPerSec=4.219083707768374, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 14500] loss=0.0317 lr=2.81e-04
[step 14550] loss=0.0000 lr=2.81e-04
[2025-08-31 01:30:19,358] [INFO] [logging.py:107:log_dist] [Rank 0] step=3650, skipped=0, lr=[0.0002810970953734883], mom=[[0.9, 0.95]]
[2025-08-31 01:30:19,359] [INFO] [timer.py:264:stop] epoch=0/micro_step=14600/global_step=3650, RunningAvgSamplesPerSec=4.208570001207101, CurrSamplesPerSec=4.226590636042959, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 14600] loss=0.0918 lr=2.81e-04
[step 14650] loss=0.0130 lr=2.81e-04
[2025-08-31 01:33:30,753] [INFO] [logging.py:107:log_dist] [Rank 0] step=3675, skipped=0, lr=[0.00028080245424587277], mom=[[0.9, 0.95]]
[2025-08-31 01:33:30,753] [INFO] [timer.py:264:stop] epoch=0/micro_step=14700/global_step=3675, RunningAvgSamplesPerSec=4.2085224059392985, CurrSamplesPerSec=4.208748530926009, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 14700] loss=0.0228 lr=2.81e-04
[step 14750] loss=0.0000 lr=2.81e-04
[2025-08-31 01:36:41,751] [INFO] [logging.py:107:log_dist] [Rank 0] step=3700, skipped=0, lr=[0.00028050569145703276], mom=[[0.9, 0.95]]
[2025-08-31 01:36:41,752] [INFO] [timer.py:264:stop] epoch=0/micro_step=14800/global_step=3700, RunningAvgSamplesPerSec=4.208539882738022, CurrSamplesPerSec=4.224983161449876, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 14800] loss=0.0001 lr=2.81e-04
[step 14850] loss=0.0000 lr=2.80e-04
[2025-08-31 01:39:53,112] [INFO] [logging.py:107:log_dist] [Rank 0] step=3725, skipped=0, lr=[0.00028020681182111567], mom=[[0.9, 0.95]]
[2025-08-31 01:39:53,112] [INFO] [timer.py:264:stop] epoch=0/micro_step=14900/global_step=3725, RunningAvgSamplesPerSec=4.20849403919651, CurrSamplesPerSec=4.219247241109838, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 14900] loss=0.1631 lr=2.80e-04
[step 14950] loss=0.0737 lr=2.80e-04
[2025-08-31 01:43:03,936] [INFO] [logging.py:107:log_dist] [Rank 0] step=3750, skipped=0, lr=[0.000279905820186609], mom=[[0.9, 0.95]]
[2025-08-31 01:43:03,937] [INFO] [timer.py:264:stop] epoch=0/micro_step=15000/global_step=3750, RunningAvgSamplesPerSec=4.208548871159144, CurrSamplesPerSec=4.228756845682628, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 15000] loss=0.0703 lr=2.80e-04
[DeepSpeed] saving checkpoint step-15000 ...
[2025-08-31 01:43:03,946] [INFO] [logging.py:107:log_dist] [Rank 0] [Torch] Checkpoint step-15000 is begin to save!
[2025-08-31 01:43:03,967] [INFO] [logging.py:107:log_dist] [Rank 0] Saving model checkpoint: cosmopedia_v2_checkpoints/step-15000/zero_pp_rank_0_mp_rank_00_model_states.pt
[step 15050] loss=0.0084 lr=2.80e-04
[2025-08-31 01:46:15,739] [INFO] [logging.py:107:log_dist] [Rank 0] step=3775, skipped=0, lr=[0.0002796027214362616], mom=[[0.9, 0.95]]
[2025-08-31 01:46:15,739] [INFO] [timer.py:264:stop] epoch=0/micro_step=15100/global_step=3775, RunningAvgSamplesPerSec=4.208561845441616, CurrSamplesPerSec=4.217502080993954, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 15100] loss=0.0000 lr=2.80e-04
[step 15150] loss=0.0064 lr=2.79e-04
[2025-08-31 01:49:26,785] [INFO] [logging.py:107:log_dist] [Rank 0] step=3800, skipped=0, lr=[0.00027929752048700416], mom=[[0.9, 0.95]]
[2025-08-31 01:49:26,785] [INFO] [timer.py:264:stop] epoch=0/micro_step=15200/global_step=3800, RunningAvgSamplesPerSec=4.208587165460035, CurrSamplesPerSec=4.225986858125622, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 15200] loss=0.0150 lr=2.79e-04
[step 15250] loss=0.0018 lr=2.79e-04
[2025-08-31 01:52:37,770] [INFO] [logging.py:107:log_dist] [Rank 0] step=3825, skipped=0, lr=[0.00027899022228986995], mom=[[0.9, 0.95]]
[2025-08-31 01:52:37,770] [INFO] [timer.py:264:stop] epoch=0/micro_step=15300/global_step=3825, RunningAvgSamplesPerSec=4.2086186595440696, CurrSamplesPerSec=4.222948099349015, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 15300] loss=0.0162 lr=2.79e-04
[step 15350] loss=0.0522 lr=2.79e-04
[2025-08-31 01:55:49,038] [INFO] [logging.py:107:log_dist] [Rank 0] step=3850, skipped=0, lr=[0.00027868083182991393], mom=[[0.9, 0.95]]
[2025-08-31 01:55:49,039] [INFO] [timer.py:264:stop] epoch=0/micro_step=15400/global_step=3850, RunningAvgSamplesPerSec=4.208609081510574, CurrSamplesPerSec=4.1287033937728, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 15400] loss=0.0000 lr=2.79e-04
[step 15450] loss=0.0000 lr=2.79e-04
[2025-08-31 01:58:59,618] [INFO] [logging.py:107:log_dist] [Rank 0] step=3875, skipped=0, lr=[0.0002783693541261326], mom=[[0.9, 0.95]]
[2025-08-31 01:58:59,619] [INFO] [timer.py:264:stop] epoch=0/micro_step=15500/global_step=3875, RunningAvgSamplesPerSec=4.208674886540137, CurrSamplesPerSec=4.2357791351546075, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 15500] loss=0.0000 lr=2.78e-04
[step 15550] loss=0.0097 lr=2.78e-04
[2025-08-31 02:02:10,289] [INFO] [logging.py:107:log_dist] [Rank 0] step=3900, skipped=0, lr=[0.0002780557942313817], mom=[[0.9, 0.95]]
[2025-08-31 02:02:10,289] [INFO] [timer.py:264:stop] epoch=0/micro_step=15600/global_step=3900, RunningAvgSamplesPerSec=4.208730019020275, CurrSamplesPerSec=4.212225546169788, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 15600] loss=0.0437 lr=2.78e-04
[step 15650] loss=0.0000 lr=2.78e-04
[2025-08-31 02:05:20,914] [INFO] [logging.py:107:log_dist] [Rank 0] step=3925, skipped=0, lr=[0.00027774015723229495], mom=[[0.9, 0.95]]
[2025-08-31 02:05:20,915] [INFO] [timer.py:264:stop] epoch=0/micro_step=15700/global_step=3925, RunningAvgSamplesPerSec=4.208783234672905, CurrSamplesPerSec=4.21861599016765, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 15700] loss=0.0000 lr=2.78e-04
[step 15750] loss=0.0001 lr=2.78e-04
[2025-08-31 02:08:31,717] [INFO] [logging.py:107:log_dist] [Rank 0] step=3950, skipped=0, lr=[0.0002774224482492013], mom=[[0.9, 0.95]]
[2025-08-31 02:08:31,718] [INFO] [timer.py:264:stop] epoch=0/micro_step=15800/global_step=3950, RunningAvgSamplesPerSec=4.20882365368341, CurrSamplesPerSec=4.154145075429651, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 15800] loss=0.0000 lr=2.77e-04
[step 15850] loss=0.0684 lr=2.77e-04
[2025-08-31 02:11:42,409] [INFO] [logging.py:107:log_dist] [Rank 0] step=3975, skipped=0, lr=[0.00027710267243604174], mom=[[0.9, 0.95]]
[2025-08-31 02:11:42,410] [INFO] [timer.py:264:stop] epoch=0/micro_step=15900/global_step=3975, RunningAvgSamplesPerSec=4.208871209479728, CurrSamplesPerSec=4.217004637483501, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 15900] loss=0.0000 lr=2.77e-04
[step 15950] loss=0.0056 lr=2.77e-04
[2025-08-31 02:14:53,155] [INFO] [logging.py:107:log_dist] [Rank 0] step=4000, skipped=0, lr=[0.00027678083498028605], mom=[[0.9, 0.95]]
[2025-08-31 02:14:53,156] [INFO] [timer.py:264:stop] epoch=0/micro_step=16000/global_step=4000, RunningAvgSamplesPerSec=4.208913547061714, CurrSamplesPerSec=4.230263461060317, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 16000] loss=0.0544 lr=2.77e-04
[step 16050] loss=0.1670 lr=2.77e-04
[2025-08-31 02:18:03,878] [INFO] [logging.py:107:log_dist] [Rank 0] step=4025, skipped=0, lr=[0.000276456941102848], mom=[[0.9, 0.95]]
[2025-08-31 02:18:03,878] [INFO] [timer.py:264:stop] epoch=0/micro_step=16100/global_step=4025, RunningAvgSamplesPerSec=4.208962613099724, CurrSamplesPerSec=4.198485140896488, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 16100] loss=0.0000 lr=2.76e-04
[step 16150] loss=0.0000 lr=2.76e-04
[2025-08-31 02:21:14,501] [INFO] [logging.py:107:log_dist] [Rank 0] step=4050, skipped=0, lr=[0.0002761309960580014], mom=[[0.9, 0.95]]
[2025-08-31 02:21:14,502] [INFO] [timer.py:264:stop] epoch=0/micro_step=16200/global_step=4050, RunningAvgSamplesPerSec=4.209028255710749, CurrSamplesPerSec=4.206665260324592, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 16200] loss=0.0000 lr=2.76e-04
[step 16250] loss=0.0693 lr=2.76e-04
[2025-08-31 02:24:25,873] [INFO] [logging.py:107:log_dist] [Rank 0] step=4075, skipped=0, lr=[0.00027580300513329437], mom=[[0.9, 0.95]]
[2025-08-31 02:24:25,874] [INFO] [timer.py:264:stop] epoch=0/micro_step=16300/global_step=4075, RunningAvgSamplesPerSec=4.209004370096831, CurrSamplesPerSec=4.230013750396201, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 16300] loss=0.3945 lr=2.76e-04
[step 16350] loss=0.0000 lr=2.76e-04
[2025-08-31 02:27:36,674] [INFO] [logging.py:107:log_dist] [Rank 0] step=4100, skipped=0, lr=[0.0002754729736494638], mom=[[0.9, 0.95]]
[2025-08-31 02:27:36,675] [INFO] [timer.py:264:stop] epoch=0/micro_step=16400/global_step=4100, RunningAvgSamplesPerSec=4.209047386871142, CurrSamplesPerSec=4.211456182595705, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 16400] loss=0.0000 lr=2.75e-04
[step 16450] loss=0.0378 lr=2.75e-04
[2025-08-31 02:30:47,687] [INFO] [logging.py:107:log_dist] [Rank 0] step=4125, skipped=0, lr=[0.00027514090696034894], mom=[[0.9, 0.95]]
[2025-08-31 02:30:47,693] [INFO] [timer.py:264:stop] epoch=0/micro_step=16500/global_step=4125, RunningAvgSamplesPerSec=4.209063105940875, CurrSamplesPerSec=4.211972805471403, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 16500] loss=0.0041 lr=2.75e-04
[step 16550] loss=0.0120 lr=2.75e-04
[2025-08-31 02:33:58,283] [INFO] [logging.py:107:log_dist] [Rank 0] step=4150, skipped=0, lr=[0.0002748068104528044], mom=[[0.9, 0.95]]
[2025-08-31 02:33:58,284] [INFO] [timer.py:264:stop] epoch=0/micro_step=16600/global_step=4150, RunningAvgSamplesPerSec=4.209127049111141, CurrSamplesPerSec=4.228917265680616, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 16600] loss=0.0192 lr=2.75e-04
[step 16650] loss=0.0112 lr=2.75e-04
[2025-08-31 02:37:09,462] [INFO] [logging.py:107:log_dist] [Rank 0] step=4175, skipped=0, lr=[0.0002744706895466132], mom=[[0.9, 0.95]]
[2025-08-31 02:37:09,462] [INFO] [timer.py:264:stop] epoch=0/micro_step=16700/global_step=4175, RunningAvgSamplesPerSec=4.209114100028836, CurrSamplesPerSec=4.23332250785012, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 16700] loss=0.0000 lr=2.74e-04
[step 16750] loss=0.0000 lr=2.74e-04
[2025-08-31 02:40:20,191] [INFO] [logging.py:107:log_dist] [Rank 0] step=4200, skipped=0, lr=[0.00027413254969439835], mom=[[0.9, 0.95]]
[2025-08-31 02:40:20,192] [INFO] [timer.py:264:stop] epoch=0/micro_step=16800/global_step=4200, RunningAvgSamplesPerSec=4.209156028132405, CurrSamplesPerSec=4.2468904314031, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 16800] loss=0.0320 lr=2.74e-04
[step 16850] loss=0.0000 lr=2.74e-04
[2025-08-31 02:43:30,890] [INFO] [logging.py:107:log_dist] [Rank 0] step=4225, skipped=0, lr=[0.00027379239638153477], mom=[[0.9, 0.95]]
[2025-08-31 02:43:30,891] [INFO] [timer.py:264:stop] epoch=0/micro_step=16900/global_step=4225, RunningAvgSamplesPerSec=4.209200785283819, CurrSamplesPerSec=4.241428766186709, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 16900] loss=0.0452 lr=2.74e-04
[step 16950] loss=0.0000 lr=2.74e-04
[2025-08-31 02:46:41,823] [INFO] [logging.py:107:log_dist] [Rank 0] step=4250, skipped=0, lr=[0.00027345023512606], mom=[[0.9, 0.95]]
[2025-08-31 02:46:41,824] [INFO] [timer.py:264:stop] epoch=0/micro_step=17000/global_step=4250, RunningAvgSamplesPerSec=4.20921686771529, CurrSamplesPerSec=4.206289929058821, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 17000] loss=0.0001 lr=2.73e-04
[step 17050] loss=0.0000 lr=2.73e-04
[2025-08-31 02:49:53,066] [INFO] [logging.py:107:log_dist] [Rank 0] step=4275, skipped=0, lr=[0.00027310607147858505], mom=[[0.9, 0.95]]
[2025-08-31 02:49:53,067] [INFO] [timer.py:264:stop] epoch=0/micro_step=17100/global_step=4275, RunningAvgSamplesPerSec=4.209197556498276, CurrSamplesPerSec=4.220550655654878, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 17100] loss=0.2949 lr=2.73e-04
[step 17150] loss=0.0000 lr=2.73e-04
[2025-08-31 02:53:04,030] [INFO] [logging.py:107:log_dist] [Rank 0] step=4300, skipped=0, lr=[0.00027275991102220393], mom=[[0.9, 0.95]]
[2025-08-31 02:53:04,031] [INFO] [timer.py:264:stop] epoch=0/micro_step=17200/global_step=4300, RunningAvgSamplesPerSec=4.209220651422277, CurrSamplesPerSec=4.243272130231245, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 17200] loss=0.4551 lr=2.73e-04
[step 17250] loss=0.0038 lr=2.73e-04
[2025-08-31 02:56:15,192] [INFO] [logging.py:107:log_dist] [Rank 0] step=4325, skipped=0, lr=[0.00027241175937240346], mom=[[0.9, 0.95]]
[2025-08-31 02:56:15,193] [INFO] [timer.py:264:stop] epoch=0/micro_step=17300/global_step=4325, RunningAvgSamplesPerSec=4.209207023893414, CurrSamplesPerSec=4.215914091296378, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 17300] loss=0.1064 lr=2.72e-04
[step 17350] loss=0.0049 lr=2.72e-04
[2025-08-31 02:59:26,324] [INFO] [logging.py:107:log_dist] [Rank 0] step=4350, skipped=0, lr=[0.0002720616221769719], mom=[[0.9, 0.95]]
[2025-08-31 02:59:26,324] [INFO] [timer.py:264:stop] epoch=0/micro_step=17400/global_step=4350, RunningAvgSamplesPerSec=4.2092127851877095, CurrSamplesPerSec=4.233439342824399, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 17400] loss=0.0002 lr=2.72e-04
[step 17450] loss=0.0496 lr=2.72e-04
[2025-08-31 03:02:37,235] [INFO] [logging.py:107:log_dist] [Rank 0] step=4375, skipped=0, lr=[0.00027170950511590757], mom=[[0.9, 0.95]]
[2025-08-31 03:02:37,236] [INFO] [timer.py:264:stop] epoch=0/micro_step=17500/global_step=4375, RunningAvgSamplesPerSec=4.209233642963456, CurrSamplesPerSec=4.221938275540226, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 17500] loss=0.0000 lr=2.72e-04
[step 17550] loss=0.0070 lr=2.72e-04
[2025-08-31 03:05:48,170] [INFO] [logging.py:107:log_dist] [Rank 0] step=4400, skipped=0, lr=[0.0002713554139013265], mom=[[0.9, 0.95]]
[2025-08-31 03:05:48,170] [INFO] [timer.py:264:stop] epoch=0/micro_step=17600/global_step=4400, RunningAvgSamplesPerSec=4.209257879121414, CurrSamplesPerSec=4.214990753871192, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 17600] loss=0.0537 lr=2.71e-04
[step 17650] loss=0.0000 lr=2.71e-04
[2025-08-31 03:08:58,529] [INFO] [logging.py:107:log_dist] [Rank 0] step=4425, skipped=0, lr=[0.0002709993542773697], mom=[[0.9, 0.95]]
[2025-08-31 03:08:58,529] [INFO] [timer.py:264:stop] epoch=0/micro_step=17700/global_step=4425, RunningAvgSamplesPerSec=4.209364229262688, CurrSamplesPerSec=4.233946147448404, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 17700] loss=0.0037 lr=2.71e-04
[step 17750] loss=0.1167 lr=2.71e-04
[2025-08-31 03:12:08,923] [INFO] [logging.py:107:log_dist] [Rank 0] step=4450, skipped=0, lr=[0.00027064133202011053], mom=[[0.9, 0.95]]
[2025-08-31 03:12:08,924] [INFO] [timer.py:264:stop] epoch=0/micro_step=17800/global_step=4450, RunningAvgSamplesPerSec=4.209452652037819, CurrSamplesPerSec=4.222791453352458, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 17800] loss=0.0000 lr=2.71e-04
[step 17850] loss=0.0295 lr=2.70e-04
[2025-08-31 03:15:19,643] [INFO] [logging.py:107:log_dist] [Rank 0] step=4475, skipped=0, lr=[0.00027028135293746016], mom=[[0.9, 0.95]]
[2025-08-31 03:15:19,644] [INFO] [timer.py:264:stop] epoch=0/micro_step=17900/global_step=4475, RunningAvgSamplesPerSec=4.209503325320871, CurrSamplesPerSec=4.227655286312256, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 17900] loss=0.0017 lr=2.70e-04
[step 17950] loss=0.0018 lr=2.70e-04
[2025-08-31 03:18:30,489] [INFO] [logging.py:107:log_dist] [Rank 0] step=4500, skipped=0, lr=[0.0002699194228690741], mom=[[0.9, 0.95]]
[2025-08-31 03:18:30,489] [INFO] [timer.py:264:stop] epoch=0/micro_step=18000/global_step=4500, RunningAvgSamplesPerSec=4.209536042040202, CurrSamplesPerSec=4.239734853074449, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 18000] loss=0.0181 lr=2.70e-04
[step 18050] loss=0.0013 lr=2.70e-04
[2025-08-31 03:21:41,897] [INFO] [logging.py:107:log_dist] [Rank 0] step=4525, skipped=0, lr=[0.00026955554768625696], mom=[[0.9, 0.95]]
[2025-08-31 03:21:41,898] [INFO] [timer.py:264:stop] epoch=0/micro_step=18100/global_step=4525, RunningAvgSamplesPerSec=4.209528173204324, CurrSamplesPerSec=4.116500444279422, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 18100] loss=0.0000 lr=2.70e-04
[step 18150] loss=0.0210 lr=2.69e-04
[2025-08-31 03:24:52,922] [INFO] [logging.py:107:log_dist] [Rank 0] step=4550, skipped=0, lr=[0.0002691897332918674], mom=[[0.9, 0.95]]
[2025-08-31 03:24:52,924] [INFO] [timer.py:264:stop] epoch=0/micro_step=18200/global_step=4550, RunningAvgSamplesPerSec=4.209542342544634, CurrSamplesPerSec=4.215000813871604, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 18200] loss=0.0459 lr=2.69e-04
[step 18250] loss=0.0000 lr=2.69e-04
[2025-08-31 03:28:03,481] [INFO] [logging.py:107:log_dist] [Rank 0] step=4575, skipped=0, lr=[0.00026882198562022257], mom=[[0.9, 0.95]]
[2025-08-31 03:28:03,482] [INFO] [timer.py:264:stop] epoch=0/micro_step=18300/global_step=4575, RunningAvgSamplesPerSec=4.209594934844855, CurrSamplesPerSec=4.16243920187308, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 18300] loss=0.0361 lr=2.69e-04
[step 18350] loss=0.0540 lr=2.69e-04
[2025-08-31 03:31:14,223] [INFO] [logging.py:107:log_dist] [Rank 0] step=4600, skipped=0, lr=[0.00026845231063700144], mom=[[0.9, 0.95]]
[2025-08-31 03:31:14,225] [INFO] [timer.py:264:stop] epoch=0/micro_step=18400/global_step=4600, RunningAvgSamplesPerSec=4.209627892225503, CurrSamplesPerSec=4.216301208359105, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 18400] loss=0.0077 lr=2.68e-04
[step 18450] loss=0.0708 lr=2.68e-04
[2025-08-31 03:34:25,655] [INFO] [logging.py:107:log_dist] [Rank 0] step=4625, skipped=0, lr=[0.00026808071433914835], mom=[[0.9, 0.95]]
[2025-08-31 03:34:25,661] [INFO] [timer.py:264:stop] epoch=0/micro_step=18500/global_step=4625, RunningAvgSamplesPerSec=4.209584145648407, CurrSamplesPerSec=4.208673701672977, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 18500] loss=0.0256 lr=2.68e-04
[step 18550] loss=0.0243 lr=2.68e-04
[2025-08-31 03:37:36,406] [INFO] [logging.py:107:log_dist] [Rank 0] step=4650, skipped=0, lr=[0.00026770720275477554], mom=[[0.9, 0.95]]
[2025-08-31 03:37:36,406] [INFO] [timer.py:264:stop] epoch=0/micro_step=18600/global_step=4650, RunningAvgSamplesPerSec=4.209624291875955, CurrSamplesPerSec=4.236089555924899, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 18600] loss=0.0645 lr=2.68e-04
[step 18650] loss=0.0118 lr=2.68e-04
[2025-08-31 03:40:47,300] [INFO] [logging.py:107:log_dist] [Rank 0] step=4675, skipped=0, lr=[0.00026733178194306547], mom=[[0.9, 0.95]]
[2025-08-31 03:40:47,301] [INFO] [timer.py:264:stop] epoch=0/micro_step=18700/global_step=4675, RunningAvgSamplesPerSec=4.209660674131159, CurrSamplesPerSec=4.202869027539333, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 18700] loss=0.0000 lr=2.67e-04
[step 18750] loss=0.0562 lr=2.67e-04
[2025-08-31 03:43:58,279] [INFO] [logging.py:107:log_dist] [Rank 0] step=4700, skipped=0, lr=[0.0002669544579941724], mom=[[0.9, 0.95]]
[2025-08-31 03:43:58,280] [INFO] [timer.py:264:stop] epoch=0/micro_step=18800/global_step=4700, RunningAvgSamplesPerSec=4.2096734679603784, CurrSamplesPerSec=4.223848873254262, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 18800] loss=0.0060 lr=2.67e-04
[step 18850] loss=0.0003 lr=2.67e-04
[2025-08-31 03:47:09,162] [INFO] [logging.py:107:log_dist] [Rank 0] step=4725, skipped=0, lr=[0.0002665752370291238], mom=[[0.9, 0.95]]
[2025-08-31 03:47:09,163] [INFO] [timer.py:264:stop] epoch=0/micro_step=18900/global_step=4725, RunningAvgSamplesPerSec=4.209699855412591, CurrSamplesPerSec=4.217279051716582, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 18900] loss=0.0000 lr=2.67e-04
[step 18950] loss=0.0204 lr=2.66e-04
[2025-08-31 03:50:20,473] [INFO] [logging.py:107:log_dist] [Rank 0] step=4750, skipped=0, lr=[0.00026619412519972074], mom=[[0.9, 0.95]]
[2025-08-31 03:50:20,473] [INFO] [timer.py:264:stop] epoch=0/micro_step=19000/global_step=4750, RunningAvgSamplesPerSec=4.209671393007495, CurrSamplesPerSec=4.206632430997209, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 19000] loss=0.0000 lr=2.66e-04
[step 19050] loss=0.0005 lr=2.66e-04
[2025-08-31 03:53:31,691] [INFO] [logging.py:107:log_dist] [Rank 0] step=4775, skipped=0, lr=[0.00026581112868843856], mom=[[0.9, 0.95]]
[2025-08-31 03:53:31,691] [INFO] [timer.py:264:stop] epoch=0/micro_step=19100/global_step=4775, RunningAvgSamplesPerSec=4.2096617730476, CurrSamplesPerSec=4.220000347743634, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 19100] loss=0.0000 lr=2.66e-04
[step 19150] loss=0.0030 lr=2.66e-04
[2025-08-31 03:56:42,867] [INFO] [logging.py:107:log_dist] [Rank 0] step=4800, skipped=0, lr=[0.0002654262537083261], mom=[[0.9, 0.95]]
[2025-08-31 03:56:42,868] [INFO] [timer.py:264:stop] epoch=0/micro_step=19200/global_step=4800, RunningAvgSamplesPerSec=4.209645314283595, CurrSamplesPerSec=4.164895517310043, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 19200] loss=0.0090 lr=2.65e-04
[step 19250] loss=0.0181 lr=2.65e-04
[2025-08-31 03:59:53,454] [INFO] [logging.py:107:log_dist] [Rank 0] step=4825, skipped=0, lr=[0.0002650395065029051], mom=[[0.9, 0.95]]
[2025-08-31 03:59:53,455] [INFO] [timer.py:264:stop] epoch=0/micro_step=19300/global_step=4825, RunningAvgSamplesPerSec=4.209698011337199, CurrSamplesPerSec=4.22151785731167, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 19300] loss=0.0003 lr=2.65e-04
[step 19350] loss=0.0000 lr=2.65e-04
[2025-08-31 04:03:04,379] [INFO] [logging.py:107:log_dist] [Rank 0] step=4850, skipped=0, lr=[0.000264650893346069], mom=[[0.9, 0.95]]
[2025-08-31 04:03:04,380] [INFO] [timer.py:264:stop] epoch=0/micro_step=19400/global_step=4850, RunningAvgSamplesPerSec=4.209721394548103, CurrSamplesPerSec=4.227030037165273, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 19400] loss=0.0420 lr=2.65e-04
[step 19450] loss=0.0232 lr=2.64e-04
[2025-08-31 04:06:15,625] [INFO] [logging.py:107:log_dist] [Rank 0] step=4875, skipped=0, lr=[0.0002642604205419812], mom=[[0.9, 0.95]]
[2025-08-31 04:06:15,625] [INFO] [timer.py:264:stop] epoch=0/micro_step=19500/global_step=4875, RunningAvgSamplesPerSec=4.20969785382335, CurrSamplesPerSec=4.100404456767099, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 19500] loss=0.0000 lr=2.64e-04
[step 19550] loss=0.0000 lr=2.64e-04
[2025-08-31 04:09:26,812] [INFO] [logging.py:107:log_dist] [Rank 0] step=4900, skipped=0, lr=[0.0002638680944249724], mom=[[0.9, 0.95]]
[2025-08-31 04:09:26,813] [INFO] [timer.py:264:stop] epoch=0/micro_step=19600/global_step=4900, RunningAvgSamplesPerSec=4.209687103363478, CurrSamplesPerSec=4.20944812178462, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 19600] loss=0.0000 lr=2.64e-04
[step 19650] loss=0.0000 lr=2.64e-04
[2025-08-31 04:12:37,795] [INFO] [logging.py:107:log_dist] [Rank 0] step=4925, skipped=0, lr=[0.00026347392135943836], mom=[[0.9, 0.95]]
[2025-08-31 04:12:37,796] [INFO] [timer.py:264:stop] epoch=0/micro_step=19700/global_step=4925, RunningAvgSamplesPerSec=4.209692314018684, CurrSamplesPerSec=4.2202129165226285, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 19700] loss=0.0000 lr=2.63e-04
[step 19750] loss=0.0000 lr=2.63e-04
[2025-08-31 04:15:48,685] [INFO] [logging.py:107:log_dist] [Rank 0] step=4950, skipped=0, lr=[0.00026307790773973637], mom=[[0.9, 0.95]]
[2025-08-31 04:15:48,685] [INFO] [timer.py:264:stop] epoch=0/micro_step=19800/global_step=4950, RunningAvgSamplesPerSec=4.209710592909852, CurrSamplesPerSec=4.240338011277031, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 19800] loss=0.0000 lr=2.63e-04
[step 19850] loss=0.0046 lr=2.63e-04
[2025-08-31 04:18:59,133] [INFO] [logging.py:107:log_dist] [Rank 0] step=4975, skipped=0, lr=[0.0002626800599900815], mom=[[0.9, 0.95]]
[2025-08-31 04:18:59,134] [INFO] [timer.py:264:stop] epoch=0/micro_step=19900/global_step=4975, RunningAvgSamplesPerSec=4.209780817314, CurrSamplesPerSec=4.220058198299114, MemAllocated=9.06GB, MaxMemAllocated=58.56GB
[step 19900] loss=0.0000 lr=2.63e-04
[step 19950] loss=0.0427 lr=2.62e-04
[Training] Reached max_steps, exiting.
[2025-08-31 04:22:14,068] [INFO] [launch.py:351:main] Process 665496 exits successfully.
[2025-08-31 04:22:14,069] [INFO] [launch.py:351:main] Process 665498 exits successfully.
[2025-08-31 04:22:14,070] [INFO] [launch.py:351:main] Process 665494 exits successfully.
[2025-08-31 04:22:15,071] [INFO] [launch.py:351:main] Process 665495 exits successfully.
[2025-08-31 04:22:15,072] [INFO] [launch.py:351:main] Process 665497 exits successfully.
[2025-08-31 04:22:16,073] [INFO] [launch.py:351:main] Process 665493 exits successfully.
[2025-08-31 04:22:17,074] [INFO] [launch.py:351:main] Process 665492 exits successfully.
[rank0]:[E831 04:52:08.919217935 ProcessGroupNCCL.cpp:685] [Rank 0] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=591180, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=1800000) ran for 1800056 milliseconds before timing out.
[rank0]:[E831 04:52:08.948680993 ProcessGroupNCCL.cpp:2252] [PG ID 0 PG GUID 0(default_pg) Rank 0]  failure detected by watchdog at work sequence id: 591180 PG status: last enqueued work: 591180, last completed work: 591179
[rank0]:[E831 04:52:08.950229087 ProcessGroupNCCL.cpp:732] Stack trace of the failed collective not found, potentially because FlightRecorder is disabled. You can enable it by setting TORCH_NCCL_TRACE_BUFFER_SIZE to a non-zero value.
[rank0]:[E831 04:52:08.950584819 ProcessGroupNCCL.cpp:2584] [PG ID 0 PG GUID 0(default_pg) Rank 0] First PG on this rank to signal dumping.
[rank0]:[E831 04:52:08.273161117 ProcessGroupNCCL.cpp:1870] [PG ID 0 PG GUID 0(default_pg) Rank 0] Received a dump signal due to a collective timeout from this local rank and we will try our best to dump the debug info. Last enqueued NCCL work: 591180, last completed NCCL work: 591179.This is most likely caused by incorrect usages of collectives, e.g., wrong sizes used across ranks, the order of collectives is not same for all ranks or the scheduled collective, for some reason, didn't run. Additionally, this can be caused by GIL deadlock or other reasons such as network errors or bugs in the communications library (e.g. NCCL), etc. 
[rank0]:[E831 04:52:08.278495773 ProcessGroupNCCL.cpp:1589] [PG ID 0 PG GUID 0(default_pg) Rank 0] ProcessGroupNCCL preparing to dump debug info. Include stack trace: 1
[rank0]:[E831 04:53:08.951312817 ProcessGroupNCCL.cpp:746] [Rank 0] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank0]:[E831 04:53:08.951614528 ProcessGroupNCCL.cpp:760] [Rank 0] To avoid data inconsistency, we are taking the entire process down.
[rank0]:[E831 04:53:08.005163899 ProcessGroupNCCL.cpp:2068] [PG ID 0 PG GUID 0(default_pg) Rank 0] Process group watchdog thread terminated with exception: [Rank 0] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=591180, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=1800000) ran for 1800056 milliseconds before timing out.
Exception raised from checkTimeout at /pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:688 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f22fb412eb0 in /home/jovyan/miniconda/envs/pytorch/lib/python3.12/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x247 (0x7f22fc2d4147 in /home/jovyan/miniconda/envs/pytorch/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::Watchdog::runLoop() + 0x1591 (0x7f22fc2d7b61 in /home/jovyan/miniconda/envs/pytorch/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::Watchdog::run() + 0xd2 (0x7f22fc2d8ec2 in /home/jovyan/miniconda/envs/pytorch/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xdbbf4 (0x7f22dfa5abf4 in /home/jovyan/miniconda/envs/pytorch/bin/../lib/libstdc++.so.6)
frame #5: <unknown function> + 0x94ac3 (0x7f2359c13ac3 in /lib/x86_64-linux-gnu/libc.so.6)
frame #6: <unknown function> + 0x126850 (0x7f2359ca5850 in /lib/x86_64-linux-gnu/libc.so.6)

[2025-08-31 04:53:20,484] [INFO] [launch.py:319:sigkill_handler] Killing subprocess 665491
[2025-08-31 04:53:20,502] [INFO] [launch.py:319:sigkill_handler] Killing subprocess 665492
[2025-08-31 04:53:20,502] [INFO] [launch.py:319:sigkill_handler] Killing subprocess 665493
[2025-08-31 04:53:20,503] [INFO] [launch.py:319:sigkill_handler] Killing subprocess 665494
[2025-08-31 04:53:20,503] [INFO] [launch.py:319:sigkill_handler] Killing subprocess 665495
[2025-08-31 04:53:20,503] [INFO] [launch.py:319:sigkill_handler] Killing subprocess 665496
[2025-08-31 04:53:20,503] [INFO] [launch.py:319:sigkill_handler] Killing subprocess 665497
[2025-08-31 04:53:20,503] [INFO] [launch.py:319:sigkill_handler] Killing subprocess 665498
[2025-08-31 04:53:20,505] [ERROR] [launch.py:325:sigkill_handler] ['/home/jovyan/miniconda/envs/pytorch/bin/python3', '-u', 'train_cosmopedia_v2.py', '--local_rank=7'] exits with return code = -6
